{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dd202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.0, 350, 4.464], [-10.0, 650, 4.464], [-10.0, 950, 4.464], [-10.0, 1250, 4.464], [10.0, 350, 4.464], [10.0, 650, 4.464], [10.0, 950, 4.464], [10.0, 1250, 4.464], [30.0, 350, 4.464], [30.0, 650, 4.464], [30.0, 950, 4.464], [30.0, 1250, 4.464], [-10.0, 350, 6.696], [-10.0, 650, 6.696], [-10.0, 950, 6.696], [-10.0, 1250, 6.696], [10.0, 350, 6.696], [10.0, 650, 6.696], [10.0, 950, 6.696], [10.0, 1250, 6.696], [30.0, 350, 6.696], [30.0, 650, 6.696], [30.0, 950, 6.696], [30.0, 1250, 6.696], [-10.0, 350, 8.928], [-10.0, 650, 8.928], [-10.0, 950, 8.928], [-10.0, 1250, 8.928], [10.0, 350, 8.928], [10.0, 650, 8.928], [10.0, 950, 8.928], [10.0, 1250, 8.928], [30.0, 350, 8.928], [30.0, 650, 8.928], [30.0, 950, 8.928], [30.0, 1250, 8.928]]\n",
      "[[ -10.     350.       4.464]\n",
      " [ -10.     650.       4.464]\n",
      " [ -10.     950.       4.464]\n",
      " [ -10.    1250.       4.464]\n",
      " [  10.     350.       4.464]\n",
      " [  10.     650.       4.464]\n",
      " [  10.     950.       4.464]\n",
      " [  10.    1250.       4.464]\n",
      " [  30.     350.       4.464]\n",
      " [  30.     650.       4.464]\n",
      " [  30.     950.       4.464]\n",
      " [  30.    1250.       4.464]\n",
      " [ -10.     350.       6.696]\n",
      " [ -10.     650.       6.696]\n",
      " [ -10.     950.       6.696]\n",
      " [ -10.    1250.       6.696]\n",
      " [  10.     350.       6.696]\n",
      " [  10.     650.       6.696]\n",
      " [  10.     950.       6.696]\n",
      " [  10.    1250.       6.696]\n",
      " [  30.     350.       6.696]\n",
      " [  30.     650.       6.696]\n",
      " [  30.     950.       6.696]\n",
      " [  30.    1250.       6.696]\n",
      " [ -10.     350.       8.928]\n",
      " [ -10.     650.       8.928]\n",
      " [ -10.     950.       8.928]\n",
      " [ -10.    1250.       8.928]\n",
      " [  10.     350.       8.928]\n",
      " [  10.     650.       8.928]\n",
      " [  10.     950.       8.928]\n",
      " [  10.    1250.       8.928]\n",
      " [  30.     350.       8.928]\n",
      " [  30.     650.       8.928]\n",
      " [  30.     950.       8.928]\n",
      " [  30.    1250.       8.928]]\n",
      "[[18.9, 80.3], [23.5, 124.6], [24.8, 138.6], [25.6, 146.9], [19.2, 83.1], [25.0, 140.5], [26.5, 157.6], [27.3, 167.5], [19.4, 84.7], [26.4, 156.7], [28.1, 177.7], [29.0, 189.4], [22.4, 75.2], [24.8, 92.2], [25.8, 99.7], [26.4, 104.6], [23.6, 83.7], [26.5, 104.9], [27.6, 113.8], [28.3, 119.6], [24.8, 92.0], [28.1, 118.2], [29.3, 128.8], [30.1, 135.5], [23.5, 62.2], [25.4, 72.5], [26.3, 77.6], [26.9, 81.1], [25.0, 70.3], [27.1, 82.7], [28.1, 88.7], [28.7, 92.8], [26.5, 78.6], [28.8, 93.5], [29.9, 100.5], [30.6, 105.2]]\n",
      "[[ 18.9  80.3]\n",
      " [ 23.5 124.6]\n",
      " [ 24.8 138.6]\n",
      " [ 25.6 146.9]\n",
      " [ 19.2  83.1]\n",
      " [ 25.  140.5]\n",
      " [ 26.5 157.6]\n",
      " [ 27.3 167.5]\n",
      " [ 19.4  84.7]\n",
      " [ 26.4 156.7]\n",
      " [ 28.1 177.7]\n",
      " [ 29.  189.4]\n",
      " [ 22.4  75.2]\n",
      " [ 24.8  92.2]\n",
      " [ 25.8  99.7]\n",
      " [ 26.4 104.6]\n",
      " [ 23.6  83.7]\n",
      " [ 26.5 104.9]\n",
      " [ 27.6 113.8]\n",
      " [ 28.3 119.6]\n",
      " [ 24.8  92. ]\n",
      " [ 28.1 118.2]\n",
      " [ 29.3 128.8]\n",
      " [ 30.1 135.5]\n",
      " [ 23.5  62.2]\n",
      " [ 25.4  72.5]\n",
      " [ 26.3  77.6]\n",
      " [ 26.9  81.1]\n",
      " [ 25.   70.3]\n",
      " [ 27.1  82.7]\n",
      " [ 28.1  88.7]\n",
      " [ 28.7  92.8]\n",
      " [ 26.5  78.6]\n",
      " [ 28.8  93.5]\n",
      " [ 29.9 100.5]\n",
      " [ 30.6 105.2]]\n"
     ]
    }
   ],
   "source": [
    "import math, numpy\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "# - split into training set and a randomly slected small validation set\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314420ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a7ce36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 800.0, 6.696]\n",
      "[26.45, 100.1]\n"
     ]
    }
   ],
   "source": [
    "ax=np.median(xarray[:,0])\n",
    "ay=np.median(yarray[:,0])\n",
    "bx=np.median(xarray[:,1])\n",
    "by=np.median(yarray[:,1])\n",
    "cx=np.median(xarray[:,2])\n",
    "Xmedian = [ax,bx,cx]\n",
    "Ymedian = [ay,by]\n",
    "print(Xmedian)\n",
    "print(Ymedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd39a2",
   "metadata": {},
   "source": [
    "## normalize the data by dividing each parameter value by its median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b585b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]\n",
      " [-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]\n",
      " [0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n"
     ]
    }
   ],
   "source": [
    "Xtask2=xarray/Xmedian\n",
    "Ytask2=yarray/Ymedian\n",
    "print(Xtask2)\n",
    "print(Ytask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f170375",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8459425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtask2, Ytask2, test_size=1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88906dc",
   "metadata": {},
   "source": [
    "##  (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1817e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-11-11 16:49:54.802620: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 16:49:54.803209: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "#2.4\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(6, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2634ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.0150)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ddeb2",
   "metadata": {},
   "source": [
    "## (d) smallest lose要小于0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128480d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "24/24 [==============================] - 0s 360us/step - loss: 0.0895\n",
      "Epoch 2/400\n",
      "24/24 [==============================] - 0s 266us/step - loss: 0.0486\n",
      "Epoch 3/400\n",
      "24/24 [==============================] - 0s 158us/step - loss: 0.0518\n",
      "Epoch 4/400\n",
      "24/24 [==============================] - 0s 260us/step - loss: 0.0814\n",
      "Epoch 5/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.0733\n",
      "Epoch 6/400\n",
      "24/24 [==============================] - 0s 674us/step - loss: 0.0527\n",
      "Epoch 7/400\n",
      "24/24 [==============================] - 0s 349us/step - loss: 0.0934\n",
      "Epoch 8/400\n",
      "24/24 [==============================] - 0s 593us/step - loss: 0.0781\n",
      "Epoch 9/400\n",
      "24/24 [==============================] - 0s 663us/step - loss: 0.1144\n",
      "Epoch 10/400\n",
      "24/24 [==============================] - 0s 416us/step - loss: 0.0907\n",
      "Epoch 11/400\n",
      "24/24 [==============================] - 0s 343us/step - loss: 0.0738\n",
      "Epoch 12/400\n",
      "24/24 [==============================] - 0s 323us/step - loss: 0.0922\n",
      "Epoch 13/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.0694\n",
      "Epoch 14/400\n",
      "24/24 [==============================] - 0s 484us/step - loss: 0.0658\n",
      "Epoch 15/400\n",
      "24/24 [==============================] - 0s 277us/step - loss: 0.0800\n",
      "Epoch 16/400\n",
      "24/24 [==============================] - 0s 263us/step - loss: 0.0809\n",
      "Epoch 17/400\n",
      "24/24 [==============================] - 0s 388us/step - loss: 0.0863\n",
      "Epoch 18/400\n",
      "24/24 [==============================] - 0s 466us/step - loss: 0.0854\n",
      "Epoch 19/400\n",
      "24/24 [==============================] - 0s 341us/step - loss: 0.0858\n",
      "Epoch 20/400\n",
      "24/24 [==============================] - 0s 298us/step - loss: 0.1119\n",
      "Epoch 21/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.0628\n",
      "Epoch 22/400\n",
      "24/24 [==============================] - 0s 263us/step - loss: 0.0896\n",
      "Epoch 23/400\n",
      "24/24 [==============================] - 0s 152us/step - loss: 0.0540\n",
      "Epoch 24/400\n",
      "24/24 [==============================] - 0s 156us/step - loss: 0.0596\n",
      "Epoch 25/400\n",
      "24/24 [==============================] - 0s 237us/step - loss: 0.0895\n",
      "Epoch 26/400\n",
      "24/24 [==============================] - 0s 229us/step - loss: 0.0872\n",
      "Epoch 27/400\n",
      "24/24 [==============================] - 0s 337us/step - loss: 0.0611\n",
      "Epoch 28/400\n",
      "24/24 [==============================] - 0s 139us/step - loss: 0.0660\n",
      "Epoch 29/400\n",
      "24/24 [==============================] - 0s 284us/step - loss: 0.0721\n",
      "Epoch 30/400\n",
      "24/24 [==============================] - 0s 142us/step - loss: 0.0710\n",
      "Epoch 31/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0576\n",
      "Epoch 32/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0558\n",
      "Epoch 33/400\n",
      "24/24 [==============================] - 0s 423us/step - loss: 0.0704\n",
      "Epoch 34/400\n",
      "24/24 [==============================] - 0s 246us/step - loss: 0.1119\n",
      "Epoch 35/400\n",
      "24/24 [==============================] - 0s 304us/step - loss: 0.1037\n",
      "Epoch 36/400\n",
      "24/24 [==============================] - 0s 233us/step - loss: 0.0714\n",
      "Epoch 37/400\n",
      "24/24 [==============================] - 0s 224us/step - loss: 0.1043\n",
      "Epoch 38/400\n",
      "24/24 [==============================] - 0s 220us/step - loss: 0.0739\n",
      "Epoch 39/400\n",
      "24/24 [==============================] - 0s 428us/step - loss: 0.1062\n",
      "Epoch 40/400\n",
      "24/24 [==============================] - 0s 574us/step - loss: 0.0492\n",
      "Epoch 41/400\n",
      "24/24 [==============================] - 0s 224us/step - loss: 0.0792\n",
      "Epoch 42/400\n",
      "24/24 [==============================] - 0s 305us/step - loss: 0.0749\n",
      "Epoch 43/400\n",
      "24/24 [==============================] - 0s 276us/step - loss: 0.0676\n",
      "Epoch 44/400\n",
      "24/24 [==============================] - 0s 249us/step - loss: 0.0726\n",
      "Epoch 45/400\n",
      "24/24 [==============================] - 0s 214us/step - loss: 0.0858\n",
      "Epoch 46/400\n",
      "24/24 [==============================] - 0s 323us/step - loss: 0.0637\n",
      "Epoch 47/400\n",
      "24/24 [==============================] - 0s 261us/step - loss: 0.0970\n",
      "Epoch 48/400\n",
      "24/24 [==============================] - 0s 423us/step - loss: 0.0540\n",
      "Epoch 49/400\n",
      "24/24 [==============================] - 0s 377us/step - loss: 0.0967\n",
      "Epoch 50/400\n",
      "24/24 [==============================] - 0s 273us/step - loss: 0.0886\n",
      "Epoch 51/400\n",
      "24/24 [==============================] - 0s 211us/step - loss: 0.1012\n",
      "Epoch 52/400\n",
      "24/24 [==============================] - 0s 269us/step - loss: 0.0499\n",
      "Epoch 53/400\n",
      "24/24 [==============================] - 0s 368us/step - loss: 0.0781\n",
      "Epoch 54/400\n",
      "24/24 [==============================] - 0s 210us/step - loss: 0.0657\n",
      "Epoch 55/400\n",
      "24/24 [==============================] - 0s 202us/step - loss: 0.0641\n",
      "Epoch 56/400\n",
      "24/24 [==============================] - 0s 424us/step - loss: 0.0765\n",
      "Epoch 57/400\n",
      "24/24 [==============================] - 0s 197us/step - loss: 0.0554\n",
      "Epoch 58/400\n",
      "24/24 [==============================] - 0s 237us/step - loss: 0.0555\n",
      "Epoch 59/400\n",
      "24/24 [==============================] - 0s 168us/step - loss: 0.0550\n",
      "Epoch 60/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0849\n",
      "Epoch 61/400\n",
      "24/24 [==============================] - 0s 339us/step - loss: 0.0882\n",
      "Epoch 62/400\n",
      "24/24 [==============================] - 0s 204us/step - loss: 0.0696\n",
      "Epoch 63/400\n",
      "24/24 [==============================] - 0s 175us/step - loss: 0.0503\n",
      "Epoch 64/400\n",
      "24/24 [==============================] - 0s 176us/step - loss: 0.0704\n",
      "Epoch 65/400\n",
      "24/24 [==============================] - 0s 284us/step - loss: 0.0756\n",
      "Epoch 66/400\n",
      "24/24 [==============================] - 0s 272us/step - loss: 0.0664\n",
      "Epoch 67/400\n",
      "24/24 [==============================] - 0s 406us/step - loss: 0.0508\n",
      "Epoch 68/400\n",
      "24/24 [==============================] - 0s 334us/step - loss: 0.0470\n",
      "Epoch 69/400\n",
      "24/24 [==============================] - 0s 233us/step - loss: 0.0869\n",
      "Epoch 70/400\n",
      "24/24 [==============================] - 0s 519us/step - loss: 0.0983\n",
      "Epoch 71/400\n",
      "24/24 [==============================] - 0s 504us/step - loss: 0.1085\n",
      "Epoch 72/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.1385\n",
      "Epoch 73/400\n",
      "24/24 [==============================] - 0s 259us/step - loss: 0.0800\n",
      "Epoch 74/400\n",
      "24/24 [==============================] - 0s 222us/step - loss: 0.0572\n",
      "Epoch 75/400\n",
      "24/24 [==============================] - 0s 183us/step - loss: 0.0537\n",
      "Epoch 76/400\n",
      "24/24 [==============================] - 0s 216us/step - loss: 0.0912\n",
      "Epoch 77/400\n",
      "24/24 [==============================] - 0s 184us/step - loss: 0.0763\n",
      "Epoch 78/400\n",
      "24/24 [==============================] - 0s 283us/step - loss: 0.0738\n",
      "Epoch 79/400\n",
      "24/24 [==============================] - 0s 308us/step - loss: 0.0737\n",
      "Epoch 80/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0514\n",
      "Epoch 81/400\n",
      "24/24 [==============================] - 0s 229us/step - loss: 0.0827\n",
      "Epoch 82/400\n",
      "24/24 [==============================] - 0s 343us/step - loss: 0.0641\n",
      "Epoch 83/400\n",
      "24/24 [==============================] - 0s 151us/step - loss: 0.0705\n",
      "Epoch 84/400\n",
      "24/24 [==============================] - 0s 270us/step - loss: 0.0623\n",
      "Epoch 85/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0569\n",
      "Epoch 86/400\n",
      "24/24 [==============================] - 0s 163us/step - loss: 0.0652\n",
      "Epoch 87/400\n",
      "24/24 [==============================] - 0s 212us/step - loss: 0.0800\n",
      "Epoch 88/400\n",
      "24/24 [==============================] - 0s 199us/step - loss: 0.0585\n",
      "Epoch 89/400\n",
      "24/24 [==============================] - 0s 171us/step - loss: 0.0554\n",
      "Epoch 90/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.0545\n",
      "Epoch 91/400\n",
      "24/24 [==============================] - 0s 380us/step - loss: 0.0660\n",
      "Epoch 92/400\n",
      "24/24 [==============================] - 0s 185us/step - loss: 0.0954\n",
      "Epoch 93/400\n",
      "24/24 [==============================] - 0s 313us/step - loss: 0.1187\n",
      "Epoch 94/400\n",
      "24/24 [==============================] - 0s 262us/step - loss: 0.0563\n",
      "Epoch 95/400\n",
      "24/24 [==============================] - 0s 341us/step - loss: 0.0641\n",
      "Epoch 96/400\n",
      "24/24 [==============================] - 0s 162us/step - loss: 0.1124\n",
      "Epoch 97/400\n",
      "24/24 [==============================] - 0s 203us/step - loss: 0.1093\n",
      "Epoch 98/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.0634\n",
      "Epoch 99/400\n",
      "24/24 [==============================] - 0s 174us/step - loss: 0.0577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/400\n",
      "24/24 [==============================] - 0s 251us/step - loss: 0.0644\n",
      "Epoch 101/400\n",
      "24/24 [==============================] - 0s 282us/step - loss: 0.0849\n",
      "Epoch 102/400\n",
      "24/24 [==============================] - 0s 306us/step - loss: 0.0661\n",
      "Epoch 103/400\n",
      "24/24 [==============================] - 0s 247us/step - loss: 0.0883\n",
      "Epoch 104/400\n",
      "24/24 [==============================] - 0s 574us/step - loss: 0.0547\n",
      "Epoch 105/400\n",
      "24/24 [==============================] - 0s 455us/step - loss: 0.0591\n",
      "Epoch 106/400\n",
      "24/24 [==============================] - 0s 192us/step - loss: 0.0943\n",
      "Epoch 107/400\n",
      "24/24 [==============================] - 0s 356us/step - loss: 0.1099\n",
      "Epoch 108/400\n",
      "24/24 [==============================] - 0s 522us/step - loss: 0.0480\n",
      "Epoch 109/400\n",
      "24/24 [==============================] - 0s 410us/step - loss: 0.0616\n",
      "Epoch 110/400\n",
      "24/24 [==============================] - 0s 157us/step - loss: 0.0854\n",
      "Epoch 111/400\n",
      "24/24 [==============================] - 0s 364us/step - loss: 0.0696\n",
      "Epoch 112/400\n",
      "24/24 [==============================] - 0s 189us/step - loss: 0.0619\n",
      "Epoch 113/400\n",
      "24/24 [==============================] - 0s 121us/step - loss: 0.0510\n",
      "Epoch 114/400\n",
      "24/24 [==============================] - 0s 177us/step - loss: 0.0798\n",
      "Epoch 115/400\n",
      "24/24 [==============================] - 0s 227us/step - loss: 0.0611\n",
      "Epoch 116/400\n",
      "24/24 [==============================] - 0s 248us/step - loss: 0.0609\n",
      "Epoch 117/400\n",
      "24/24 [==============================] - 0s 157us/step - loss: 0.0449\n",
      "Epoch 118/400\n",
      "24/24 [==============================] - 0s 132us/step - loss: 0.0582\n",
      "Epoch 119/400\n",
      "24/24 [==============================] - 0s 141us/step - loss: 0.0686\n",
      "Epoch 120/400\n",
      "24/24 [==============================] - 0s 135us/step - loss: 0.0861\n",
      "Epoch 121/400\n",
      "24/24 [==============================] - 0s 240us/step - loss: 0.0644\n",
      "Epoch 122/400\n",
      "24/24 [==============================] - 0s 149us/step - loss: 0.0666\n",
      "Epoch 123/400\n",
      "24/24 [==============================] - 0s 188us/step - loss: 0.0536\n",
      "Epoch 124/400\n",
      "24/24 [==============================] - 0s 209us/step - loss: 0.0833\n",
      "Epoch 125/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.1055\n",
      "Epoch 126/400\n",
      "24/24 [==============================] - 0s 316us/step - loss: 0.0642\n",
      "Epoch 127/400\n",
      "24/24 [==============================] - 0s 178us/step - loss: 0.0789\n",
      "Epoch 128/400\n",
      "24/24 [==============================] - 0s 547us/step - loss: 0.0718\n",
      "Epoch 129/400\n",
      "24/24 [==============================] - 0s 247us/step - loss: 0.0602\n",
      "Epoch 130/400\n",
      "24/24 [==============================] - 0s 347us/step - loss: 0.1043\n",
      "Epoch 131/400\n",
      "24/24 [==============================] - 0s 396us/step - loss: 0.1015\n",
      "Epoch 132/400\n",
      "24/24 [==============================] - 0s 286us/step - loss: 0.0630\n",
      "Epoch 133/400\n",
      "24/24 [==============================] - 0s 151us/step - loss: 0.0552\n",
      "Epoch 134/400\n",
      "24/24 [==============================] - 0s 475us/step - loss: 0.0592\n",
      "Epoch 135/400\n",
      "24/24 [==============================] - 0s 401us/step - loss: 0.0719\n",
      "Epoch 136/400\n",
      "24/24 [==============================] - 0s 276us/step - loss: 0.0484\n",
      "Epoch 137/400\n",
      "24/24 [==============================] - 0s 344us/step - loss: 0.0717\n",
      "Epoch 138/400\n",
      "24/24 [==============================] - 0s 313us/step - loss: 0.0618\n",
      "Epoch 139/400\n",
      "24/24 [==============================] - 0s 267us/step - loss: 0.0716\n",
      "Epoch 140/400\n",
      "24/24 [==============================] - 0s 226us/step - loss: 0.0458\n",
      "Epoch 141/400\n",
      "24/24 [==============================] - 0s 303us/step - loss: 0.0722\n",
      "Epoch 142/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.0488\n",
      "Epoch 143/400\n",
      "24/24 [==============================] - 0s 412us/step - loss: 0.0771\n",
      "Epoch 144/400\n",
      "24/24 [==============================] - 0s 487us/step - loss: 0.0707\n",
      "Epoch 145/400\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0620\n",
      "Epoch 146/400\n",
      "24/24 [==============================] - 0s 413us/step - loss: 0.0439\n",
      "Epoch 147/400\n",
      "24/24 [==============================] - 0s 438us/step - loss: 0.1030\n",
      "Epoch 148/400\n",
      "24/24 [==============================] - 0s 150us/step - loss: 0.0809\n",
      "Epoch 149/400\n",
      "24/24 [==============================] - 0s 438us/step - loss: 0.0707\n",
      "Epoch 150/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.1113\n",
      "Epoch 151/400\n",
      "24/24 [==============================] - 0s 328us/step - loss: 0.0735\n",
      "Epoch 152/400\n",
      "24/24 [==============================] - 0s 146us/step - loss: 0.0631\n",
      "Epoch 153/400\n",
      "24/24 [==============================] - 0s 390us/step - loss: 0.0736\n",
      "Epoch 154/400\n",
      "24/24 [==============================] - 0s 432us/step - loss: 0.0710\n",
      "Epoch 155/400\n",
      "24/24 [==============================] - 0s 184us/step - loss: 0.0549\n",
      "Epoch 156/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.0924\n",
      "Epoch 157/400\n",
      "24/24 [==============================] - 0s 181us/step - loss: 0.0589\n",
      "Epoch 158/400\n",
      "24/24 [==============================] - 0s 484us/step - loss: 0.0640\n",
      "Epoch 159/400\n",
      "24/24 [==============================] - 0s 228us/step - loss: 0.0800\n",
      "Epoch 160/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.0830\n",
      "Epoch 161/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.0517\n",
      "Epoch 162/400\n",
      "24/24 [==============================] - 0s 364us/step - loss: 0.0639\n",
      "Epoch 163/400\n",
      "24/24 [==============================] - 0s 209us/step - loss: 0.0786\n",
      "Epoch 164/400\n",
      "24/24 [==============================] - 0s 504us/step - loss: 0.0697\n",
      "Epoch 165/400\n",
      "24/24 [==============================] - 0s 377us/step - loss: 0.0569\n",
      "Epoch 166/400\n",
      "24/24 [==============================] - 0s 364us/step - loss: 0.0571\n",
      "Epoch 167/400\n",
      "24/24 [==============================] - 0s 498us/step - loss: 0.0720\n",
      "Epoch 168/400\n",
      "24/24 [==============================] - 0s 659us/step - loss: 0.0659\n",
      "Epoch 169/400\n",
      "24/24 [==============================] - 0s 213us/step - loss: 0.0612\n",
      "Epoch 170/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.0633\n",
      "Epoch 171/400\n",
      "24/24 [==============================] - 0s 345us/step - loss: 0.0662\n",
      "Epoch 172/400\n",
      "24/24 [==============================] - 0s 198us/step - loss: 0.0518\n",
      "Epoch 173/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.0683\n",
      "Epoch 174/400\n",
      "24/24 [==============================] - 0s 295us/step - loss: 0.0584\n",
      "Epoch 175/400\n",
      "24/24 [==============================] - 0s 254us/step - loss: 0.0517\n",
      "Epoch 176/400\n",
      "24/24 [==============================] - 0s 289us/step - loss: 0.0666\n",
      "Epoch 177/400\n",
      "24/24 [==============================] - 0s 233us/step - loss: 0.0544\n",
      "Epoch 178/400\n",
      "24/24 [==============================] - 0s 205us/step - loss: 0.0620\n",
      "Epoch 179/400\n",
      "24/24 [==============================] - 0s 465us/step - loss: 0.0839\n",
      "Epoch 180/400\n",
      "24/24 [==============================] - 0s 290us/step - loss: 0.0659\n",
      "Epoch 181/400\n",
      "24/24 [==============================] - 0s 455us/step - loss: 0.0639\n",
      "Epoch 182/400\n",
      "24/24 [==============================] - 0s 463us/step - loss: 0.0543\n",
      "Epoch 183/400\n",
      "24/24 [==============================] - 0s 157us/step - loss: 0.0509\n",
      "Epoch 184/400\n",
      "24/24 [==============================] - 0s 408us/step - loss: 0.0702\n",
      "Epoch 185/400\n",
      "24/24 [==============================] - 0s 458us/step - loss: 0.0809\n",
      "Epoch 186/400\n",
      "24/24 [==============================] - 0s 195us/step - loss: 0.0717\n",
      "Epoch 187/400\n",
      "24/24 [==============================] - 0s 412us/step - loss: 0.0831\n",
      "Epoch 188/400\n",
      "24/24 [==============================] - 0s 210us/step - loss: 0.1070\n",
      "Epoch 189/400\n",
      "24/24 [==============================] - 0s 875us/step - loss: 0.0567\n",
      "Epoch 190/400\n",
      "24/24 [==============================] - 0s 531us/step - loss: 0.0657\n",
      "Epoch 191/400\n",
      "24/24 [==============================] - 0s 982us/step - loss: 0.0758\n",
      "Epoch 192/400\n",
      "24/24 [==============================] - 0s 704us/step - loss: 0.0522\n",
      "Epoch 193/400\n",
      "24/24 [==============================] - 0s 543us/step - loss: 0.0503\n",
      "Epoch 194/400\n",
      "24/24 [==============================] - 0s 345us/step - loss: 0.0494\n",
      "Epoch 195/400\n",
      "24/24 [==============================] - 0s 296us/step - loss: 0.0589\n",
      "Epoch 196/400\n",
      "24/24 [==============================] - 0s 314us/step - loss: 0.0648\n",
      "Epoch 197/400\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/400\n",
      "24/24 [==============================] - 0s 392us/step - loss: 0.0944\n",
      "Epoch 199/400\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0566\n",
      "Epoch 200/400\n",
      "24/24 [==============================] - 0s 231us/step - loss: 0.0584\n",
      "Epoch 201/400\n",
      "24/24 [==============================] - 0s 213us/step - loss: 0.0575\n",
      "Epoch 202/400\n",
      "24/24 [==============================] - 0s 321us/step - loss: 0.0742\n",
      "Epoch 203/400\n",
      "24/24 [==============================] - 0s 346us/step - loss: 0.0511\n",
      "Epoch 204/400\n",
      "24/24 [==============================] - 0s 539us/step - loss: 0.0606\n",
      "Epoch 205/400\n",
      "24/24 [==============================] - 0s 175us/step - loss: 0.0496\n",
      "Epoch 206/400\n",
      "24/24 [==============================] - 0s 164us/step - loss: 0.0495\n",
      "Epoch 207/400\n",
      "24/24 [==============================] - 0s 394us/step - loss: 0.1046\n",
      "Epoch 208/400\n",
      "24/24 [==============================] - 0s 268us/step - loss: 0.0958\n",
      "Epoch 209/400\n",
      "24/24 [==============================] - 0s 232us/step - loss: 0.0571\n",
      "Epoch 210/400\n",
      "24/24 [==============================] - 0s 150us/step - loss: 0.0706\n",
      "Epoch 211/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.0683\n",
      "Epoch 212/400\n",
      "24/24 [==============================] - 0s 179us/step - loss: 0.1025\n",
      "Epoch 213/400\n",
      "24/24 [==============================] - 0s 161us/step - loss: 0.0637\n",
      "Epoch 214/400\n",
      "24/24 [==============================] - 0s 147us/step - loss: 0.0530\n",
      "Epoch 215/400\n",
      "24/24 [==============================] - 0s 199us/step - loss: 0.0961\n",
      "Epoch 216/400\n",
      "24/24 [==============================] - 0s 142us/step - loss: 0.0545\n",
      "Epoch 217/400\n",
      "24/24 [==============================] - 0s 121us/step - loss: 0.0757\n",
      "Epoch 218/400\n",
      "24/24 [==============================] - 0s 148us/step - loss: 0.0623\n",
      "Epoch 219/400\n",
      "24/24 [==============================] - 0s 131us/step - loss: 0.0759\n",
      "Epoch 220/400\n",
      "24/24 [==============================] - 0s 124us/step - loss: 0.0671\n",
      "Epoch 221/400\n",
      "24/24 [==============================] - 0s 222us/step - loss: 0.0800\n",
      "Epoch 222/400\n",
      "24/24 [==============================] - 0s 555us/step - loss: 0.0826\n",
      "Epoch 223/400\n",
      "24/24 [==============================] - 0s 643us/step - loss: 0.0546\n",
      "Epoch 224/400\n",
      "24/24 [==============================] - 0s 430us/step - loss: 0.0665\n",
      "Epoch 225/400\n",
      "24/24 [==============================] - 0s 623us/step - loss: 0.0382\n",
      "Epoch 226/400\n",
      "24/24 [==============================] - 0s 550us/step - loss: 0.0519\n",
      "Epoch 227/400\n",
      "24/24 [==============================] - 0s 199us/step - loss: 0.0593\n",
      "Epoch 228/400\n",
      "24/24 [==============================] - 0s 492us/step - loss: 0.0520\n",
      "Epoch 229/400\n",
      "24/24 [==============================] - 0s 225us/step - loss: 0.0536\n",
      "Epoch 230/400\n",
      "24/24 [==============================] - 0s 411us/step - loss: 0.0806\n",
      "Epoch 231/400\n",
      "24/24 [==============================] - 0s 284us/step - loss: 0.0727\n",
      "Epoch 232/400\n",
      "24/24 [==============================] - 0s 350us/step - loss: 0.0681\n",
      "Epoch 233/400\n",
      "24/24 [==============================] - 0s 520us/step - loss: 0.1063\n",
      "Epoch 234/400\n",
      "24/24 [==============================] - 0s 251us/step - loss: 0.0559\n",
      "Epoch 235/400\n",
      "24/24 [==============================] - 0s 178us/step - loss: 0.0519\n",
      "Epoch 236/400\n",
      "24/24 [==============================] - 0s 217us/step - loss: 0.0715\n",
      "Epoch 237/400\n",
      "24/24 [==============================] - 0s 176us/step - loss: 0.0624\n",
      "Epoch 238/400\n",
      "24/24 [==============================] - 0s 192us/step - loss: 0.0584\n",
      "Epoch 239/400\n",
      "24/24 [==============================] - 0s 311us/step - loss: 0.0509\n",
      "Epoch 240/400\n",
      "24/24 [==============================] - 0s 393us/step - loss: 0.0604\n",
      "Epoch 241/400\n",
      "24/24 [==============================] - 0s 190us/step - loss: 0.0685\n",
      "Epoch 242/400\n",
      "24/24 [==============================] - 0s 501us/step - loss: 0.0661\n",
      "Epoch 243/400\n",
      "24/24 [==============================] - 0s 439us/step - loss: 0.0445\n",
      "Epoch 244/400\n",
      "24/24 [==============================] - 0s 337us/step - loss: 0.0816\n",
      "Epoch 245/400\n",
      "24/24 [==============================] - 0s 199us/step - loss: 0.0722\n",
      "Epoch 246/400\n",
      "24/24 [==============================] - 0s 282us/step - loss: 0.0723\n",
      "Epoch 247/400\n",
      "24/24 [==============================] - 0s 339us/step - loss: 0.0752\n",
      "Epoch 248/400\n",
      "24/24 [==============================] - 0s 161us/step - loss: 0.0795\n",
      "Epoch 249/400\n",
      "24/24 [==============================] - 0s 281us/step - loss: 0.0818\n",
      "Epoch 250/400\n",
      "24/24 [==============================] - 0s 142us/step - loss: 0.0557\n",
      "Epoch 251/400\n",
      "24/24 [==============================] - 0s 330us/step - loss: 0.0616\n",
      "Epoch 252/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.0814\n",
      "Epoch 253/400\n",
      "24/24 [==============================] - 0s 313us/step - loss: 0.0573\n",
      "Epoch 254/400\n",
      "24/24 [==============================] - 0s 251us/step - loss: 0.0644\n",
      "Epoch 255/400\n",
      "24/24 [==============================] - 0s 237us/step - loss: 0.0593\n",
      "Epoch 256/400\n",
      "24/24 [==============================] - 0s 144us/step - loss: 0.0566\n",
      "Epoch 257/400\n",
      "24/24 [==============================] - 0s 177us/step - loss: 0.0441\n",
      "Epoch 258/400\n",
      "24/24 [==============================] - 0s 182us/step - loss: 0.0584\n",
      "Epoch 259/400\n",
      "24/24 [==============================] - 0s 133us/step - loss: 0.0497\n",
      "Epoch 260/400\n",
      "24/24 [==============================] - 0s 222us/step - loss: 0.0597\n",
      "Epoch 261/400\n",
      "24/24 [==============================] - 0s 162us/step - loss: 0.0801\n",
      "Epoch 262/400\n",
      "24/24 [==============================] - 0s 204us/step - loss: 0.0714\n",
      "Epoch 263/400\n",
      "24/24 [==============================] - 0s 268us/step - loss: 0.1006\n",
      "Epoch 264/400\n",
      "24/24 [==============================] - 0s 178us/step - loss: 0.0663\n",
      "Epoch 265/400\n",
      "24/24 [==============================] - 0s 247us/step - loss: 0.0644\n",
      "Epoch 266/400\n",
      "24/24 [==============================] - 0s 414us/step - loss: 0.0580\n",
      "Epoch 267/400\n",
      "24/24 [==============================] - 0s 341us/step - loss: 0.0464\n",
      "Epoch 268/400\n",
      "24/24 [==============================] - 0s 309us/step - loss: 0.0749\n",
      "Epoch 269/400\n",
      "24/24 [==============================] - 0s 153us/step - loss: 0.0908\n",
      "Epoch 270/400\n",
      "24/24 [==============================] - 0s 677us/step - loss: 0.0603\n",
      "Epoch 271/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.0594\n",
      "Epoch 272/400\n",
      "24/24 [==============================] - 0s 352us/step - loss: 0.0551\n",
      "Epoch 273/400\n",
      "24/24 [==============================] - 0s 487us/step - loss: 0.0688\n",
      "Epoch 274/400\n",
      "24/24 [==============================] - 0s 182us/step - loss: 0.0489\n",
      "Epoch 275/400\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.0495\n",
      "Epoch 276/400\n",
      "24/24 [==============================] - 0s 327us/step - loss: 0.0710\n",
      "Epoch 277/400\n",
      "24/24 [==============================] - 0s 238us/step - loss: 0.0593\n",
      "Epoch 278/400\n",
      "24/24 [==============================] - 0s 357us/step - loss: 0.0583\n",
      "Epoch 279/400\n",
      "24/24 [==============================] - 0s 158us/step - loss: 0.0882\n",
      "Epoch 280/400\n",
      "24/24 [==============================] - 0s 174us/step - loss: 0.0579\n",
      "Epoch 281/400\n",
      "24/24 [==============================] - 0s 244us/step - loss: 0.0622\n",
      "Epoch 282/400\n",
      "24/24 [==============================] - 0s 162us/step - loss: 0.0565\n",
      "Epoch 283/400\n",
      "24/24 [==============================] - 0s 194us/step - loss: 0.0683\n",
      "Epoch 284/400\n",
      "24/24 [==============================] - 0s 312us/step - loss: 0.0688\n",
      "Epoch 285/400\n",
      "24/24 [==============================] - 0s 148us/step - loss: 0.0708\n",
      "Epoch 286/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.0582\n",
      "Epoch 287/400\n",
      "24/24 [==============================] - 0s 276us/step - loss: 0.0618\n",
      "Epoch 288/400\n",
      "24/24 [==============================] - 0s 315us/step - loss: 0.0581\n",
      "Epoch 289/400\n",
      "24/24 [==============================] - 0s 350us/step - loss: 0.0775\n",
      "Epoch 290/400\n",
      "24/24 [==============================] - 0s 295us/step - loss: 0.0488\n",
      "Epoch 291/400\n",
      "24/24 [==============================] - 0s 326us/step - loss: 0.0503\n",
      "Epoch 292/400\n",
      "24/24 [==============================] - 0s 189us/step - loss: 0.0572\n",
      "Epoch 293/400\n",
      "24/24 [==============================] - 0s 605us/step - loss: 0.0614\n",
      "Epoch 294/400\n",
      "24/24 [==============================] - 0s 635us/step - loss: 0.0690\n",
      "Epoch 295/400\n",
      "24/24 [==============================] - 0s 351us/step - loss: 0.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/400\n",
      "24/24 [==============================] - 0s 317us/step - loss: 0.0437\n",
      "Epoch 297/400\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0798\n",
      "Epoch 298/400\n",
      "24/24 [==============================] - 0s 514us/step - loss: 0.0513\n",
      "Epoch 299/400\n",
      "24/24 [==============================] - 0s 366us/step - loss: 0.0485\n",
      "Epoch 300/400\n",
      "24/24 [==============================] - 0s 355us/step - loss: 0.0730\n",
      "Epoch 301/400\n",
      "24/24 [==============================] - 0s 151us/step - loss: 0.0781\n",
      "Epoch 302/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.0733\n",
      "Epoch 303/400\n",
      "24/24 [==============================] - 0s 183us/step - loss: 0.0864\n",
      "Epoch 304/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.0752\n",
      "Epoch 305/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.0548\n",
      "Epoch 306/400\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0727\n",
      "Epoch 307/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.0591\n",
      "Epoch 308/400\n",
      "24/24 [==============================] - 0s 351us/step - loss: 0.0445\n",
      "Epoch 309/400\n",
      "24/24 [==============================] - 0s 640us/step - loss: 0.0409\n",
      "Epoch 310/400\n",
      "24/24 [==============================] - 0s 162us/step - loss: 0.0462\n",
      "Epoch 311/400\n",
      "24/24 [==============================] - 0s 541us/step - loss: 0.0479\n",
      "Epoch 312/400\n",
      "24/24 [==============================] - 0s 206us/step - loss: 0.0918\n",
      "Epoch 313/400\n",
      "24/24 [==============================] - 0s 478us/step - loss: 0.0567\n",
      "Epoch 314/400\n",
      "24/24 [==============================] - 0s 258us/step - loss: 0.0506\n",
      "Epoch 315/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.0709\n",
      "Epoch 316/400\n",
      "24/24 [==============================] - 0s 193us/step - loss: 0.0524\n",
      "Epoch 317/400\n",
      "24/24 [==============================] - 0s 450us/step - loss: 0.0622\n",
      "Epoch 318/400\n",
      "24/24 [==============================] - 0s 887us/step - loss: 0.0500\n",
      "Epoch 319/400\n",
      "24/24 [==============================] - 0s 513us/step - loss: 0.0851\n",
      "Epoch 320/400\n",
      "24/24 [==============================] - 0s 532us/step - loss: 0.0482\n",
      "Epoch 321/400\n",
      "24/24 [==============================] - 0s 361us/step - loss: 0.0614\n",
      "Epoch 322/400\n",
      "24/24 [==============================] - 0s 435us/step - loss: 0.0620\n",
      "Epoch 323/400\n",
      "24/24 [==============================] - 0s 216us/step - loss: 0.0862\n",
      "Epoch 324/400\n",
      "24/24 [==============================] - 0s 158us/step - loss: 0.0492\n",
      "Epoch 325/400\n",
      "24/24 [==============================] - 0s 391us/step - loss: 0.0666\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00325: early stopping\n",
      "best epoch =  225\n",
      "smallest loss = 0.03817697986960411\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 100, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "#historyData = model.fit(xarray,yarray,epochs=500,callbacks=[es])\n",
    "historyData = model.fit(X_train,Y_train,epochs=400,callbacks=[es]) \n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dec40c",
   "metadata": {},
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9520a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.2 , power=  83.1 ,  predicted voltage_to_load =  21.637829959392548 , predicted power=  99.81179780960082\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  29.0 , power=  189.4 ,  predicted voltage_to_load =  31.290964019298553 , predicted power=  211.09411916732788\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  29.300000000000004 , power=  128.8 ,  predicted voltage_to_load =  29.65025587081909 , predicted power=  146.61701726913452\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  25.0 , power=  140.5 ,  predicted voltage_to_load =  24.813680946826935 , predicted power=  130.75886834859847\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  25.0 , power=  70.3 ,  predicted voltage_to_load =  24.341101190447805 , predicted power=  71.41076785326004\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  29.9 , power=  100.5 ,  predicted voltage_to_load =  28.951374423503875 , predicted power=  106.04026813507079\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  25.6 , power=  146.9 ,  predicted voltage_to_load =  26.28976333737373 , predicted power=  154.58928267955778\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  18.9 , power=  80.3 ,  predicted voltage_to_load =  19.90305580496788 , predicted power=  85.6007998228073\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.0 ,  predicted voltage_to_load =  25.21783243715763 , predicted power=  95.48245247602462\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  26.3 , power=  77.6 ,  predicted voltage_to_load =  25.22703787088394 , predicted power=  75.11263024210929\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  26.5 , power=  78.6 ,  predicted voltage_to_load =  25.915209862589837 , predicted power=  78.95192326307296\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  27.099999999999998 , power=  82.7 ,  predicted voltage_to_load =  26.090422105789184 , predicted power=  78.92915538549423\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  28.799999999999997 , power=  93.5 ,  predicted voltage_to_load =  27.827091264724732 , predicted power=  90.97857728004455\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  27.599999999999998 , power=  113.80000000000001 ,  predicted voltage_to_load =  27.584631586074828 , predicted power=  118.79125807285308\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  26.5 , power=  104.9 ,  predicted voltage_to_load =  25.487788599729537 , predicted power=  95.67521573305129\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  25.4 , power=  72.5 ,  predicted voltage_to_load =  24.570332098007203 , predicted power=  72.84535893201827\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  4.464 , voltage_to_load=  26.5 , power=  157.6 ,  predicted voltage_to_load =  27.70823569893837 , predicted power=  160.3302244901657\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.2 ,  predicted voltage_to_load =  23.382465389370918 , predicted power=  83.85212420225143\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  28.699999999999996 , power=  92.8 ,  predicted voltage_to_load =  27.314907175302505 , predicted power=  96.86350682377815\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  25.8 , power=  99.7 ,  predicted voltage_to_load =  25.12772355377674 , predicted power=  96.09791904091834\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  27.3 , power=  167.5 ,  predicted voltage_to_load =  28.915788698196412 , predicted power=  183.3717461824417\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  26.9 , power=  81.1 ,  predicted voltage_to_load =  25.371556401252747 , predicted power=  79.10770661830901\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  22.4 , power=  75.2 ,  predicted voltage_to_load =  21.403566727042197 , predicted power=  73.90632054805755\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  26.4 , power=  156.7 ,  predicted voltage_to_load =  27.90309954881668 , predicted power=  161.36461164951322\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "outpt=[]\n",
    "\n",
    "Tamed = 10\n",
    "IDmed = 800.\n",
    "RLmed = 6.696\n",
    "VLmed = 26.45\n",
    "Wdmed = 100.1\n",
    "\n",
    "\n",
    "#first point (row [0])comparison of data and prediction\n",
    "# put in a loop to print comparion for all data points\n",
    "for i in range(len(X_train)):\n",
    "    \n",
    "    test = [[ X_train[i][0] , X_train[i][1] , X_train[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    print ('row [0] data:  T1= ', X_train[i][0]*Tamed, ', gam= ', X_train[i][1]*IDmed, \\\n",
    "        ', qsol= ', X_train[i][2]*RLmed,', voltage_to_load= ', Y_train[i][0]*VLmed,\\\n",
    "        ', power= ', Y_train[i][1]*Wdmed,',  predicted voltage_to_load = ', outpt[0][0]*VLmed,\\\n",
    "           ', predicted power= ', outpt[0][1]*Wdmed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442c013",
   "metadata": {},
   "source": [
    "# (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1579c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.2 , power=  83.1 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  29.0 , power=  189.4 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  29.300000000000004 , power=  128.8 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  25.0 , power=  140.5 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  25.0 , power=  70.3 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  29.9 , power=  100.5 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  25.6 , power=  146.9 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  18.9 , power=  80.3 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.0 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  26.3 , power=  77.6 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  26.5 , power=  78.6 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  27.099999999999998 , power=  82.7 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  28.799999999999997 , power=  93.5 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  27.599999999999998 , power=  113.80000000000001 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  26.5 , power=  104.9 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  25.4 , power=  72.5 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  4.464 , voltage_to_load=  26.5 , power=  157.6 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.2 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  28.699999999999996 , power=  92.8 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  25.8 , power=  99.7 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  27.3 , power=  167.5 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  26.9 , power=  81.1 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  22.4 , power=  75.2 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  26.4 , power=  156.7 ,  predicted voltage_to_load =  28.3 , predicted power=  119.6\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "outpt=[]\n",
    "\n",
    "Tamed = 10\n",
    "IDmed = 800.\n",
    "RLmed = 6.696\n",
    "VLmed = 26.45\n",
    "Wdmed = 100.1\n",
    "\n",
    "\n",
    "#first point (row [0])comparison of data and prediction\n",
    "# put in a loop to print comparion for all data points\n",
    "for i in range(len(X_train)):\n",
    "    \n",
    "    test = [[ X_train[i][0] , X_train[i][1] , X_train[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "\n",
    "    print ('row [0] data:  T1= ', X_train[i][0]*Tamed, ', gam= ', X_train[i][1]*IDmed, \\\n",
    "        ', qsol= ', X_train[i][2]*RLmed,', voltage_to_load= ', Y_train[i][0]*VLmed,\\\n",
    "        ', power= ', Y_train[i][1]*Wdmed,',  predicted voltage_to_load = ', Y_test[0][0]*VLmed,\\\n",
    "           ', predicted power= ', Y_test[0][1]*Wdmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
