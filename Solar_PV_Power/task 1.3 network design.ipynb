{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dd202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.0, 350, 4.464], [-10.0, 650, 4.464], [-10.0, 950, 4.464], [-10.0, 1250, 4.464], [10.0, 350, 4.464], [10.0, 650, 4.464], [10.0, 950, 4.464], [10.0, 1250, 4.464], [30.0, 350, 4.464], [30.0, 650, 4.464], [30.0, 950, 4.464], [30.0, 1250, 4.464], [-10.0, 350, 6.696], [-10.0, 650, 6.696], [-10.0, 950, 6.696], [-10.0, 1250, 6.696], [10.0, 350, 6.696], [10.0, 650, 6.696], [10.0, 950, 6.696], [10.0, 1250, 6.696], [30.0, 350, 6.696], [30.0, 650, 6.696], [30.0, 950, 6.696], [30.0, 1250, 6.696], [-10.0, 350, 8.928], [-10.0, 650, 8.928], [-10.0, 950, 8.928], [-10.0, 1250, 8.928], [10.0, 350, 8.928], [10.0, 650, 8.928], [10.0, 950, 8.928], [10.0, 1250, 8.928], [30.0, 350, 8.928], [30.0, 650, 8.928], [30.0, 950, 8.928], [30.0, 1250, 8.928]]\n",
      "[[ -10.     350.       4.464]\n",
      " [ -10.     650.       4.464]\n",
      " [ -10.     950.       4.464]\n",
      " [ -10.    1250.       4.464]\n",
      " [  10.     350.       4.464]\n",
      " [  10.     650.       4.464]\n",
      " [  10.     950.       4.464]\n",
      " [  10.    1250.       4.464]\n",
      " [  30.     350.       4.464]\n",
      " [  30.     650.       4.464]\n",
      " [  30.     950.       4.464]\n",
      " [  30.    1250.       4.464]\n",
      " [ -10.     350.       6.696]\n",
      " [ -10.     650.       6.696]\n",
      " [ -10.     950.       6.696]\n",
      " [ -10.    1250.       6.696]\n",
      " [  10.     350.       6.696]\n",
      " [  10.     650.       6.696]\n",
      " [  10.     950.       6.696]\n",
      " [  10.    1250.       6.696]\n",
      " [  30.     350.       6.696]\n",
      " [  30.     650.       6.696]\n",
      " [  30.     950.       6.696]\n",
      " [  30.    1250.       6.696]\n",
      " [ -10.     350.       8.928]\n",
      " [ -10.     650.       8.928]\n",
      " [ -10.     950.       8.928]\n",
      " [ -10.    1250.       8.928]\n",
      " [  10.     350.       8.928]\n",
      " [  10.     650.       8.928]\n",
      " [  10.     950.       8.928]\n",
      " [  10.    1250.       8.928]\n",
      " [  30.     350.       8.928]\n",
      " [  30.     650.       8.928]\n",
      " [  30.     950.       8.928]\n",
      " [  30.    1250.       8.928]]\n",
      "[[18.9, 80.3], [23.5, 124.6], [24.8, 138.6], [25.6, 146.9], [19.2, 83.1], [25.0, 140.5], [26.5, 157.6], [27.3, 167.5], [19.4, 84.7], [26.4, 156.7], [28.1, 177.7], [29.0, 189.4], [22.4, 75.2], [24.8, 92.2], [25.8, 99.7], [26.4, 104.6], [23.6, 83.7], [26.5, 104.9], [27.6, 113.8], [28.3, 119.6], [24.8, 92.0], [28.1, 118.2], [29.3, 128.8], [30.1, 135.5], [23.5, 62.2], [25.4, 72.5], [26.3, 77.6], [26.9, 81.1], [25.0, 70.3], [27.1, 82.7], [28.1, 88.7], [28.7, 92.8], [26.5, 78.6], [28.8, 93.5], [29.9, 100.5], [30.6, 105.2]]\n",
      "[[ 18.9  80.3]\n",
      " [ 23.5 124.6]\n",
      " [ 24.8 138.6]\n",
      " [ 25.6 146.9]\n",
      " [ 19.2  83.1]\n",
      " [ 25.  140.5]\n",
      " [ 26.5 157.6]\n",
      " [ 27.3 167.5]\n",
      " [ 19.4  84.7]\n",
      " [ 26.4 156.7]\n",
      " [ 28.1 177.7]\n",
      " [ 29.  189.4]\n",
      " [ 22.4  75.2]\n",
      " [ 24.8  92.2]\n",
      " [ 25.8  99.7]\n",
      " [ 26.4 104.6]\n",
      " [ 23.6  83.7]\n",
      " [ 26.5 104.9]\n",
      " [ 27.6 113.8]\n",
      " [ 28.3 119.6]\n",
      " [ 24.8  92. ]\n",
      " [ 28.1 118.2]\n",
      " [ 29.3 128.8]\n",
      " [ 30.1 135.5]\n",
      " [ 23.5  62.2]\n",
      " [ 25.4  72.5]\n",
      " [ 26.3  77.6]\n",
      " [ 26.9  81.1]\n",
      " [ 25.   70.3]\n",
      " [ 27.1  82.7]\n",
      " [ 28.1  88.7]\n",
      " [ 28.7  92.8]\n",
      " [ 26.5  78.6]\n",
      " [ 28.8  93.5]\n",
      " [ 29.9 100.5]\n",
      " [ 30.6 105.2]]\n"
     ]
    }
   ],
   "source": [
    "import math, numpy\n",
    "#Part 1 input data: Air temp (degC), ID (W/sqm), load resistance (ohms)\n",
    "# - split into training set and a randomly slected small validation set\n",
    "xdata = [[-10.0, 350, 4.464], \n",
    "  [-10.0, 650, 4.464], \n",
    "  [-10.0, 950, 4.464], \n",
    "  [-10.0, 1250, 4.464], \n",
    "  [10.0, 350, 4.464], \n",
    "  [10.0, 650, 4.464], \n",
    "  [10.0, 950, 4.464], \n",
    "  [10.0, 1250, 4.464], \n",
    "  [30.0, 350, 4.464], \n",
    "  [30.0, 650, 4.464], \n",
    "  [30.0, 950, 4.464], \n",
    "  [30.0, 1250, 4.464], \n",
    "  [-10.0, 350, 6.696], \n",
    "  [-10.0, 650, 6.696], \n",
    "  [-10.0, 950, 6.696], \n",
    "  [-10.0, 1250, 6.696], \n",
    "  [10.0, 350, 6.696], \n",
    "  [10.0, 650, 6.696], \n",
    "  [10.0, 950, 6.696], \n",
    "  [10.0, 1250, 6.696], \n",
    "  [30.0, 350, 6.696], \n",
    "  [30.0, 650, 6.696], \n",
    "  [30.0, 950, 6.696], \n",
    "  [30.0, 1250, 6.696], \n",
    "  [-10.0, 350, 8.928], \n",
    "  [-10.0, 650, 8.928], \n",
    "  [-10.0, 950, 8.928], \n",
    "  [-10.0, 1250, 8.928], \n",
    "  [10.0, 350, 8.928], \n",
    "  [10.0, 650, 8.928], \n",
    "  [10.0, 950, 8.928], \n",
    "  [10.0, 1250, 8.928], \n",
    "  [30.0, 350, 8.928], \n",
    "  [30.0, 650, 8.928], \n",
    "  [30.0, 950, 8.928], \n",
    "  [30.0, 1250, 8.928]] \n",
    "\n",
    "\n",
    "#Part 1 output data: VL (V) and Power out (W)\n",
    "ydata = [[18.9, 80.3], \n",
    " [23.5, 124.6], \n",
    " [24.8, 138.6], \n",
    " [25.6, 146.9], \n",
    " [19.2, 83.1], \n",
    " [25.0, 140.5], \n",
    " [26.5, 157.6], \n",
    " [27.3, 167.5],  \n",
    " [19.4, 84.7], \n",
    " [26.4, 156.7], \n",
    " [28.1, 177.7], \n",
    " [29.0, 189.4],\n",
    " [22.4, 75.2], \n",
    " [24.8, 92.2], \n",
    " [25.8, 99.7], \n",
    " [26.4, 104.6], \n",
    " [23.6, 83.7], \n",
    " [26.5, 104.9], \n",
    " [27.6, 113.8], \n",
    " [28.3, 119.6], \n",
    " [24.8, 92.0], \n",
    " [28.1, 118.2], \n",
    " [29.3, 128.8], \n",
    " [30.1, 135.5],  \n",
    " [23.5, 62.2], \n",
    " [25.4, 72.5], \n",
    " [26.3, 77.6], \n",
    " [26.9, 81.1],  \n",
    " [25.0, 70.3], \n",
    " [27.1, 82.7], \n",
    " [28.1, 88.7], \n",
    " [28.7, 92.8],  \n",
    " [26.5, 78.6], \n",
    " [28.8, 93.5], \n",
    " [29.9, 100.5], \n",
    " [30.6, 105.2]] \n",
    "\n",
    "\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314420ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a7ce36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 800.0, 6.696]\n",
      "[26.45, 100.1]\n"
     ]
    }
   ],
   "source": [
    "ax=np.median(xarray[:,0])\n",
    "ay=np.median(yarray[:,0])\n",
    "bx=np.median(xarray[:,1])\n",
    "by=np.median(yarray[:,1])\n",
    "cx=np.median(xarray[:,2])\n",
    "Xmedian = [ax,bx,cx]\n",
    "Ymedian = [ay,by]\n",
    "print(Xmedian)\n",
    "print(Ymedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd39a2",
   "metadata": {},
   "source": [
    "## normalize the data by dividing each parameter value by its median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b585b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.4375      0.66666667]\n",
      " [-1.          0.8125      0.66666667]\n",
      " [-1.          1.1875      0.66666667]\n",
      " [-1.          1.5625      0.66666667]\n",
      " [ 1.          0.4375      0.66666667]\n",
      " [ 1.          0.8125      0.66666667]\n",
      " [ 1.          1.1875      0.66666667]\n",
      " [ 1.          1.5625      0.66666667]\n",
      " [ 3.          0.4375      0.66666667]\n",
      " [ 3.          0.8125      0.66666667]\n",
      " [ 3.          1.1875      0.66666667]\n",
      " [ 3.          1.5625      0.66666667]\n",
      " [-1.          0.4375      1.        ]\n",
      " [-1.          0.8125      1.        ]\n",
      " [-1.          1.1875      1.        ]\n",
      " [-1.          1.5625      1.        ]\n",
      " [ 1.          0.4375      1.        ]\n",
      " [ 1.          0.8125      1.        ]\n",
      " [ 1.          1.1875      1.        ]\n",
      " [ 1.          1.5625      1.        ]\n",
      " [ 3.          0.4375      1.        ]\n",
      " [ 3.          0.8125      1.        ]\n",
      " [ 3.          1.1875      1.        ]\n",
      " [ 3.          1.5625      1.        ]\n",
      " [-1.          0.4375      1.33333333]\n",
      " [-1.          0.8125      1.33333333]\n",
      " [-1.          1.1875      1.33333333]\n",
      " [-1.          1.5625      1.33333333]\n",
      " [ 1.          0.4375      1.33333333]\n",
      " [ 1.          0.8125      1.33333333]\n",
      " [ 1.          1.1875      1.33333333]\n",
      " [ 1.          1.5625      1.33333333]\n",
      " [ 3.          0.4375      1.33333333]\n",
      " [ 3.          0.8125      1.33333333]\n",
      " [ 3.          1.1875      1.33333333]\n",
      " [ 3.          1.5625      1.33333333]]\n",
      "[[0.71455577 0.8021978 ]\n",
      " [0.88846881 1.24475524]\n",
      " [0.93761815 1.38461538]\n",
      " [0.96786389 1.46753247]\n",
      " [0.72589792 0.83016983]\n",
      " [0.94517958 1.4035964 ]\n",
      " [1.00189036 1.57442557]\n",
      " [1.03213611 1.67332667]\n",
      " [0.73345936 0.84615385]\n",
      " [0.99810964 1.56543457]\n",
      " [1.06238185 1.77522478]\n",
      " [1.09640832 1.89210789]\n",
      " [0.84688091 0.75124875]\n",
      " [0.93761815 0.92107892]\n",
      " [0.97542533 0.996004  ]\n",
      " [0.99810964 1.04495504]\n",
      " [0.89224953 0.83616384]\n",
      " [1.00189036 1.04795205]\n",
      " [1.04347826 1.13686314]\n",
      " [1.06994329 1.19480519]\n",
      " [0.93761815 0.91908092]\n",
      " [1.06238185 1.18081918]\n",
      " [1.10775047 1.28671329]\n",
      " [1.13799622 1.35364635]\n",
      " [0.88846881 0.62137862]\n",
      " [0.96030246 0.72427572]\n",
      " [0.99432892 0.77522478]\n",
      " [1.01701323 0.81018981]\n",
      " [0.94517958 0.7022977 ]\n",
      " [1.02457467 0.82617383]\n",
      " [1.06238185 0.88611389]\n",
      " [1.08506616 0.92707293]\n",
      " [1.00189036 0.78521479]\n",
      " [1.08884688 0.93406593]\n",
      " [1.13043478 1.003996  ]\n",
      " [1.15689981 1.05094905]]\n"
     ]
    }
   ],
   "source": [
    "Xtask2=xarray/Xmedian\n",
    "Ytask2=yarray/Ymedian\n",
    "print(Xtask2)\n",
    "print(Ytask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f170375",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8459425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtask2, Ytask2, test_size=1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88906dc",
   "metadata": {},
   "source": [
    "##  (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1817e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-11-11 19:22:42.675837: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 19:22:42.676164: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "#2.4\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(6, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(12, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2634ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.0150)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ddeb2",
   "metadata": {},
   "source": [
    "## (d) smallest lose要小于0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128480d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.5252\n",
      "Epoch 2/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 2.9555\n",
      "Epoch 3/400\n",
      "24/24 [==============================] - 0s 288us/step - loss: 0.7627\n",
      "Epoch 4/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.3518\n",
      "Epoch 5/400\n",
      "24/24 [==============================] - 0s 325us/step - loss: 0.2640\n",
      "Epoch 6/400\n",
      "24/24 [==============================] - 0s 350us/step - loss: 0.3191\n",
      "Epoch 7/400\n",
      "24/24 [==============================] - 0s 533us/step - loss: 0.3777\n",
      "Epoch 8/400\n",
      "24/24 [==============================] - 0s 274us/step - loss: 0.4272\n",
      "Epoch 9/400\n",
      "24/24 [==============================] - 0s 244us/step - loss: 0.1952\n",
      "Epoch 10/400\n",
      "24/24 [==============================] - 0s 503us/step - loss: 0.2205\n",
      "Epoch 11/400\n",
      "24/24 [==============================] - 0s 248us/step - loss: 0.2847\n",
      "Epoch 12/400\n",
      "24/24 [==============================] - 0s 300us/step - loss: 0.4078\n",
      "Epoch 13/400\n",
      "24/24 [==============================] - 0s 534us/step - loss: 0.1966\n",
      "Epoch 14/400\n",
      "24/24 [==============================] - 0s 407us/step - loss: 0.2952\n",
      "Epoch 15/400\n",
      "24/24 [==============================] - 0s 447us/step - loss: 0.2612\n",
      "Epoch 16/400\n",
      "24/24 [==============================] - 0s 456us/step - loss: 0.4020\n",
      "Epoch 17/400\n",
      "24/24 [==============================] - 0s 355us/step - loss: 0.1745\n",
      "Epoch 18/400\n",
      "24/24 [==============================] - 0s 187us/step - loss: 0.1839\n",
      "Epoch 19/400\n",
      "24/24 [==============================] - 0s 267us/step - loss: 0.2889\n",
      "Epoch 20/400\n",
      "24/24 [==============================] - 0s 383us/step - loss: 0.3256\n",
      "Epoch 21/400\n",
      "24/24 [==============================] - 0s 329us/step - loss: 0.2573\n",
      "Epoch 22/400\n",
      "24/24 [==============================] - 0s 221us/step - loss: 0.3953\n",
      "Epoch 23/400\n",
      "24/24 [==============================] - 0s 509us/step - loss: 0.1726\n",
      "Epoch 24/400\n",
      "24/24 [==============================] - 0s 763us/step - loss: 0.2240\n",
      "Epoch 25/400\n",
      "24/24 [==============================] - 0s 349us/step - loss: 0.3106\n",
      "Epoch 26/400\n",
      "24/24 [==============================] - 0s 251us/step - loss: 0.2427\n",
      "Epoch 27/400\n",
      "24/24 [==============================] - 0s 169us/step - loss: 0.3873\n",
      "Epoch 28/400\n",
      "24/24 [==============================] - 0s 682us/step - loss: 0.1825\n",
      "Epoch 29/400\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2565\n",
      "Epoch 30/400\n",
      "24/24 [==============================] - 0s 393us/step - loss: 0.3215\n",
      "Epoch 31/400\n",
      "24/24 [==============================] - 0s 203us/step - loss: 0.1826\n",
      "Epoch 32/400\n",
      "24/24 [==============================] - 0s 303us/step - loss: 0.3366\n",
      "Epoch 33/400\n",
      "24/24 [==============================] - 0s 261us/step - loss: 0.1590\n",
      "Epoch 34/400\n",
      "24/24 [==============================] - 0s 308us/step - loss: 0.1502\n",
      "Epoch 35/400\n",
      "24/24 [==============================] - 0s 207us/step - loss: 0.2846\n",
      "Epoch 36/400\n",
      "24/24 [==============================] - 0s 198us/step - loss: 0.3623\n",
      "Epoch 37/400\n",
      "24/24 [==============================] - 0s 195us/step - loss: 0.1458\n",
      "Epoch 38/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.1454\n",
      "Epoch 39/400\n",
      "24/24 [==============================] - 0s 229us/step - loss: 0.2042\n",
      "Epoch 40/400\n",
      "24/24 [==============================] - 0s 200us/step - loss: 0.2955\n",
      "Epoch 41/400\n",
      "24/24 [==============================] - 0s 345us/step - loss: 0.2038\n",
      "Epoch 42/400\n",
      "24/24 [==============================] - 0s 316us/step - loss: 0.3179\n",
      "Epoch 43/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.1621\n",
      "Epoch 44/400\n",
      "24/24 [==============================] - 0s 349us/step - loss: 0.2147\n",
      "Epoch 45/400\n",
      "24/24 [==============================] - 0s 503us/step - loss: 0.2601\n",
      "Epoch 46/400\n",
      "24/24 [==============================] - 0s 211us/step - loss: 0.2186\n",
      "Epoch 47/400\n",
      "24/24 [==============================] - 0s 284us/step - loss: 0.3229\n",
      "Epoch 48/400\n",
      "24/24 [==============================] - 0s 276us/step - loss: 0.1626\n",
      "Epoch 49/400\n",
      "24/24 [==============================] - 0s 312us/step - loss: 0.2076\n",
      "Epoch 50/400\n",
      "24/24 [==============================] - 0s 474us/step - loss: 0.2621\n",
      "Epoch 51/400\n",
      "24/24 [==============================] - 0s 308us/step - loss: 0.1872\n",
      "Epoch 52/400\n",
      "24/24 [==============================] - 0s 321us/step - loss: 0.3011\n",
      "Epoch 53/400\n",
      "24/24 [==============================] - 0s 434us/step - loss: 0.1624\n",
      "Epoch 54/400\n",
      "24/24 [==============================] - 0s 933us/step - loss: 0.1880\n",
      "Epoch 55/400\n",
      "24/24 [==============================] - 0s 596us/step - loss: 0.2132\n",
      "Epoch 56/400\n",
      "24/24 [==============================] - 0s 214us/step - loss: 0.1449\n",
      "Epoch 57/400\n",
      "24/24 [==============================] - 0s 384us/step - loss: 0.3049\n",
      "Epoch 58/400\n",
      "24/24 [==============================] - 0s 369us/step - loss: 0.1673\n",
      "Epoch 59/400\n",
      "24/24 [==============================] - 0s 162us/step - loss: 0.1685\n",
      "Epoch 60/400\n",
      "24/24 [==============================] - 0s 418us/step - loss: 0.2164\n",
      "Epoch 61/400\n",
      "24/24 [==============================] - 0s 247us/step - loss: 0.1890\n",
      "Epoch 62/400\n",
      "24/24 [==============================] - 0s 511us/step - loss: 0.2751\n",
      "Epoch 63/400\n",
      "24/24 [==============================] - 0s 267us/step - loss: 0.1603\n",
      "Epoch 64/400\n",
      "24/24 [==============================] - 0s 302us/step - loss: 0.1560\n",
      "Epoch 65/400\n",
      "24/24 [==============================] - 0s 329us/step - loss: 0.2245\n",
      "Epoch 66/400\n",
      "24/24 [==============================] - 0s 289us/step - loss: 0.1597\n",
      "Epoch 67/400\n",
      "24/24 [==============================] - 0s 210us/step - loss: 0.2236\n",
      "Epoch 68/400\n",
      "24/24 [==============================] - 0s 139us/step - loss: 0.1521\n",
      "Epoch 69/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.1944\n",
      "Epoch 70/400\n",
      "24/24 [==============================] - 0s 241us/step - loss: 0.1647\n",
      "Epoch 71/400\n",
      "24/24 [==============================] - 0s 236us/step - loss: 0.2589\n",
      "Epoch 72/400\n",
      "24/24 [==============================] - 0s 169us/step - loss: 0.1437\n",
      "Epoch 73/400\n",
      "24/24 [==============================] - 0s 153us/step - loss: 0.1508\n",
      "Epoch 74/400\n",
      "24/24 [==============================] - 0s 212us/step - loss: 0.1872\n",
      "Epoch 75/400\n",
      "24/24 [==============================] - 0s 303us/step - loss: 0.2071\n",
      "Epoch 76/400\n",
      "24/24 [==============================] - 0s 601us/step - loss: 0.2403\n",
      "Epoch 77/400\n",
      "24/24 [==============================] - 0s 260us/step - loss: 0.1433\n",
      "Epoch 78/400\n",
      "24/24 [==============================] - 0s 361us/step - loss: 0.1178\n",
      "Epoch 79/400\n",
      "24/24 [==============================] - 0s 685us/step - loss: 0.1681\n",
      "Epoch 80/400\n",
      "24/24 [==============================] - 0s 322us/step - loss: 0.1039\n",
      "Epoch 81/400\n",
      "24/24 [==============================] - 0s 386us/step - loss: 0.1525\n",
      "Epoch 82/400\n",
      "24/24 [==============================] - 0s 631us/step - loss: 0.2599\n",
      "Epoch 83/400\n",
      "24/24 [==============================] - 0s 266us/step - loss: 0.2176\n",
      "Epoch 84/400\n",
      "24/24 [==============================] - 0s 304us/step - loss: 0.1628\n",
      "Epoch 85/400\n",
      "24/24 [==============================] - 0s 177us/step - loss: 0.1414\n",
      "Epoch 86/400\n",
      "24/24 [==============================] - 0s 293us/step - loss: 0.1363\n",
      "Epoch 87/400\n",
      "24/24 [==============================] - 0s 152us/step - loss: 0.2168\n",
      "Epoch 88/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.1943\n",
      "Epoch 89/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.2028\n",
      "Epoch 90/400\n",
      "24/24 [==============================] - 0s 141us/step - loss: 0.1167\n",
      "Epoch 91/400\n",
      "24/24 [==============================] - 0s 153us/step - loss: 0.1149\n",
      "Epoch 92/400\n",
      "24/24 [==============================] - 0s 177us/step - loss: 0.2220\n",
      "Epoch 93/400\n",
      "24/24 [==============================] - 0s 152us/step - loss: 0.1949\n",
      "Epoch 94/400\n",
      "24/24 [==============================] - 0s 149us/step - loss: 0.1106\n",
      "Epoch 95/400\n",
      "24/24 [==============================] - 0s 216us/step - loss: 0.1270\n",
      "Epoch 96/400\n",
      "24/24 [==============================] - 0s 133us/step - loss: 0.2749\n",
      "Epoch 97/400\n",
      "24/24 [==============================] - 0s 154us/step - loss: 0.1389\n",
      "Epoch 98/400\n",
      "24/24 [==============================] - 0s 230us/step - loss: 0.1103\n",
      "Epoch 99/400\n",
      "24/24 [==============================] - 0s 196us/step - loss: 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/400\n",
      "24/24 [==============================] - 0s 194us/step - loss: 0.1154\n",
      "Epoch 101/400\n",
      "24/24 [==============================] - 0s 207us/step - loss: 0.1419\n",
      "Epoch 102/400\n",
      "24/24 [==============================] - 0s 168us/step - loss: 0.1758\n",
      "Epoch 103/400\n",
      "24/24 [==============================] - 0s 362us/step - loss: 0.2515\n",
      "Epoch 104/400\n",
      "24/24 [==============================] - 0s 324us/step - loss: 0.1677\n",
      "Epoch 105/400\n",
      "24/24 [==============================] - 0s 431us/step - loss: 0.0997\n",
      "Epoch 106/400\n",
      "24/24 [==============================] - 0s 304us/step - loss: 0.1167\n",
      "Epoch 107/400\n",
      "24/24 [==============================] - 0s 189us/step - loss: 0.2206\n",
      "Epoch 108/400\n",
      "24/24 [==============================] - 0s 361us/step - loss: 0.1578\n",
      "Epoch 109/400\n",
      "24/24 [==============================] - 0s 201us/step - loss: 0.1330\n",
      "Epoch 110/400\n",
      "24/24 [==============================] - 0s 169us/step - loss: 0.1636\n",
      "Epoch 111/400\n",
      "24/24 [==============================] - 0s 201us/step - loss: 0.2503\n",
      "Epoch 112/400\n",
      "24/24 [==============================] - 0s 296us/step - loss: 0.1425\n",
      "Epoch 113/400\n",
      "24/24 [==============================] - 0s 275us/step - loss: 0.1149\n",
      "Epoch 114/400\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1341\n",
      "Epoch 115/400\n",
      "24/24 [==============================] - 0s 265us/step - loss: 0.1159\n",
      "Epoch 116/400\n",
      "24/24 [==============================] - 0s 188us/step - loss: 0.1163\n",
      "Epoch 117/400\n",
      "24/24 [==============================] - 0s 372us/step - loss: 0.1128\n",
      "Epoch 118/400\n",
      "24/24 [==============================] - 0s 304us/step - loss: 0.1224\n",
      "Epoch 119/400\n",
      "24/24 [==============================] - 0s 209us/step - loss: 0.1849\n",
      "Epoch 120/400\n",
      "24/24 [==============================] - 0s 256us/step - loss: 0.2465\n",
      "Epoch 121/400\n",
      "24/24 [==============================] - 0s 218us/step - loss: 0.1502\n",
      "Epoch 122/400\n",
      "24/24 [==============================] - 0s 515us/step - loss: 0.1038\n",
      "Epoch 123/400\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.1394\n",
      "Epoch 124/400\n",
      "24/24 [==============================] - 0s 259us/step - loss: 0.1024\n",
      "Epoch 125/400\n",
      "24/24 [==============================] - 0s 305us/step - loss: 0.1541\n",
      "Epoch 126/400\n",
      "24/24 [==============================] - 0s 209us/step - loss: 0.2088\n",
      "Epoch 127/400\n",
      "24/24 [==============================] - 0s 185us/step - loss: 0.1266\n",
      "Epoch 128/400\n",
      "24/24 [==============================] - 0s 183us/step - loss: 0.1399\n",
      "Epoch 129/400\n",
      "24/24 [==============================] - 0s 318us/step - loss: 0.1662\n",
      "Epoch 130/400\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.1641\n",
      "Epoch 131/400\n",
      "24/24 [==============================] - 0s 181us/step - loss: 0.0971\n",
      "Epoch 132/400\n",
      "24/24 [==============================] - 0s 214us/step - loss: 0.1081\n",
      "Epoch 133/400\n",
      "24/24 [==============================] - 0s 246us/step - loss: 0.1315\n",
      "Epoch 134/400\n",
      "24/24 [==============================] - 0s 217us/step - loss: 0.1316\n",
      "Epoch 135/400\n",
      "24/24 [==============================] - 0s 366us/step - loss: 0.2229\n",
      "Epoch 136/400\n",
      "24/24 [==============================] - 0s 184us/step - loss: 0.1980\n",
      "Epoch 137/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1300\n",
      "Epoch 138/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1168\n",
      "Epoch 139/400\n",
      "24/24 [==============================] - 0s 369us/step - loss: 0.1470\n",
      "Epoch 140/400\n",
      "24/24 [==============================] - 0s 323us/step - loss: 0.1480\n",
      "Epoch 141/400\n",
      "24/24 [==============================] - 0s 219us/step - loss: 0.1110\n",
      "Epoch 142/400\n",
      "24/24 [==============================] - 0s 220us/step - loss: 0.1780\n",
      "Epoch 143/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.1463\n",
      "Epoch 144/400\n",
      "24/24 [==============================] - 0s 470us/step - loss: 0.1065\n",
      "Epoch 145/400\n",
      "24/24 [==============================] - 0s 298us/step - loss: 0.1174\n",
      "Epoch 146/400\n",
      "24/24 [==============================] - 0s 181us/step - loss: 0.1169\n",
      "Epoch 147/400\n",
      "24/24 [==============================] - 0s 414us/step - loss: 0.1366\n",
      "Epoch 148/400\n",
      "24/24 [==============================] - 0s 293us/step - loss: 0.1250\n",
      "Epoch 149/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.1240\n",
      "Epoch 150/400\n",
      "24/24 [==============================] - 0s 276us/step - loss: 0.1299\n",
      "Epoch 151/400\n",
      "24/24 [==============================] - 0s 226us/step - loss: 0.2106\n",
      "Epoch 152/400\n",
      "24/24 [==============================] - 0s 295us/step - loss: 0.1315\n",
      "Epoch 153/400\n",
      "24/24 [==============================] - 0s 352us/step - loss: 0.1127\n",
      "Epoch 154/400\n",
      "24/24 [==============================] - 0s 183us/step - loss: 0.1581\n",
      "Epoch 155/400\n",
      "24/24 [==============================] - 0s 164us/step - loss: 0.1891\n",
      "Epoch 156/400\n",
      "24/24 [==============================] - 0s 177us/step - loss: 0.1229\n",
      "Epoch 157/400\n",
      "24/24 [==============================] - 0s 199us/step - loss: 0.1268\n",
      "Epoch 158/400\n",
      "24/24 [==============================] - 0s 331us/step - loss: 0.1332\n",
      "Epoch 159/400\n",
      "24/24 [==============================] - 0s 371us/step - loss: 0.1015\n",
      "Epoch 160/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.1236\n",
      "Epoch 161/400\n",
      "24/24 [==============================] - 0s 291us/step - loss: 0.1649\n",
      "Epoch 162/400\n",
      "24/24 [==============================] - 0s 202us/step - loss: 0.1269\n",
      "Epoch 163/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.1115\n",
      "Epoch 164/400\n",
      "24/24 [==============================] - 0s 265us/step - loss: 0.1673\n",
      "Epoch 165/400\n",
      "24/24 [==============================] - 0s 200us/step - loss: 0.1904\n",
      "Epoch 166/400\n",
      "24/24 [==============================] - 0s 234us/step - loss: 0.1319\n",
      "Epoch 167/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.1172\n",
      "Epoch 168/400\n",
      "24/24 [==============================] - 0s 201us/step - loss: 0.1126\n",
      "Epoch 169/400\n",
      "24/24 [==============================] - 0s 213us/step - loss: 0.1062\n",
      "Epoch 170/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.0954\n",
      "Epoch 171/400\n",
      "24/24 [==============================] - 0s 231us/step - loss: 0.1058\n",
      "Epoch 172/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.1009\n",
      "Epoch 173/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.1390\n",
      "Epoch 174/400\n",
      "24/24 [==============================] - 0s 284us/step - loss: 0.1670\n",
      "Epoch 175/400\n",
      "24/24 [==============================] - 0s 340us/step - loss: 0.1811\n",
      "Epoch 176/400\n",
      "24/24 [==============================] - 0s 244us/step - loss: 0.1469\n",
      "Epoch 177/400\n",
      "24/24 [==============================] - 0s 236us/step - loss: 0.1292\n",
      "Epoch 178/400\n",
      "24/24 [==============================] - 0s 484us/step - loss: 0.1580\n",
      "Epoch 179/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.1040\n",
      "Epoch 180/400\n",
      "24/24 [==============================] - 0s 190us/step - loss: 0.1067\n",
      "Epoch 181/400\n",
      "24/24 [==============================] - 0s 423us/step - loss: 0.1177\n",
      "Epoch 182/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.1253\n",
      "Epoch 183/400\n",
      "24/24 [==============================] - 0s 288us/step - loss: 0.1889\n",
      "Epoch 184/400\n",
      "24/24 [==============================] - 0s 213us/step - loss: 0.1909\n",
      "Epoch 185/400\n",
      "24/24 [==============================] - 0s 336us/step - loss: 0.1127\n",
      "Epoch 186/400\n",
      "24/24 [==============================] - 0s 311us/step - loss: 0.0933\n",
      "Epoch 187/400\n",
      "24/24 [==============================] - 0s 169us/step - loss: 0.1177\n",
      "Epoch 188/400\n",
      "24/24 [==============================] - 0s 627us/step - loss: 0.1049\n",
      "Epoch 189/400\n",
      "24/24 [==============================] - 0s 174us/step - loss: 0.1066\n",
      "Epoch 190/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.1014\n",
      "Epoch 191/400\n",
      "24/24 [==============================] - 0s 459us/step - loss: 0.0953\n",
      "Epoch 192/400\n",
      "24/24 [==============================] - 0s 435us/step - loss: 0.0953\n",
      "Epoch 193/400\n",
      "24/24 [==============================] - 0s 301us/step - loss: 0.1030\n",
      "Epoch 194/400\n",
      "24/24 [==============================] - 0s 184us/step - loss: 0.0894\n",
      "Epoch 195/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.1853\n",
      "Epoch 196/400\n",
      "24/24 [==============================] - 0s 159us/step - loss: 0.1643\n",
      "Epoch 197/400\n",
      "24/24 [==============================] - 0s 313us/step - loss: 0.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/400\n",
      "24/24 [==============================] - 0s 214us/step - loss: 0.1828\n",
      "Epoch 199/400\n",
      "24/24 [==============================] - 0s 243us/step - loss: 0.1338\n",
      "Epoch 200/400\n",
      "24/24 [==============================] - 0s 236us/step - loss: 0.1218\n",
      "Epoch 201/400\n",
      "24/24 [==============================] - 0s 326us/step - loss: 0.1463\n",
      "Epoch 202/400\n",
      "24/24 [==============================] - 0s 196us/step - loss: 0.0990\n",
      "Epoch 203/400\n",
      "24/24 [==============================] - 0s 154us/step - loss: 0.1085\n",
      "Epoch 204/400\n",
      "24/24 [==============================] - 0s 243us/step - loss: 0.0888\n",
      "Epoch 205/400\n",
      "24/24 [==============================] - 0s 238us/step - loss: 0.1496\n",
      "Epoch 206/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.1071\n",
      "Epoch 207/400\n",
      "24/24 [==============================] - 0s 282us/step - loss: 0.1204\n",
      "Epoch 208/400\n",
      "24/24 [==============================] - 0s 239us/step - loss: 0.1186\n",
      "Epoch 209/400\n",
      "24/24 [==============================] - 0s 155us/step - loss: 0.1030\n",
      "Epoch 210/400\n",
      "24/24 [==============================] - 0s 200us/step - loss: 0.0939\n",
      "Epoch 211/400\n",
      "24/24 [==============================] - 0s 195us/step - loss: 0.0964\n",
      "Epoch 212/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0887\n",
      "Epoch 213/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.0938\n",
      "Epoch 214/400\n",
      "24/24 [==============================] - 0s 260us/step - loss: 0.1104\n",
      "Epoch 215/400\n",
      "24/24 [==============================] - 0s 321us/step - loss: 0.1036\n",
      "Epoch 216/400\n",
      "24/24 [==============================] - 0s 182us/step - loss: 0.0901\n",
      "Epoch 217/400\n",
      "24/24 [==============================] - 0s 283us/step - loss: 0.1478\n",
      "Epoch 218/400\n",
      "24/24 [==============================] - 0s 204us/step - loss: 0.1773\n",
      "Epoch 219/400\n",
      "24/24 [==============================] - 0s 247us/step - loss: 0.1718\n",
      "Epoch 220/400\n",
      "24/24 [==============================] - 0s 229us/step - loss: 0.1435\n",
      "Epoch 221/400\n",
      "24/24 [==============================] - 0s 185us/step - loss: 0.1321\n",
      "Epoch 222/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1344\n",
      "Epoch 223/400\n",
      "24/24 [==============================] - 0s 191us/step - loss: 0.0805\n",
      "Epoch 224/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.0941\n",
      "Epoch 225/400\n",
      "24/24 [==============================] - 0s 262us/step - loss: 0.1529\n",
      "Epoch 226/400\n",
      "24/24 [==============================] - 0s 241us/step - loss: 0.1786\n",
      "Epoch 227/400\n",
      "24/24 [==============================] - 0s 181us/step - loss: 0.1026\n",
      "Epoch 228/400\n",
      "24/24 [==============================] - 0s 230us/step - loss: 0.0787\n",
      "Epoch 229/400\n",
      "24/24 [==============================] - 0s 238us/step - loss: 0.0923\n",
      "Epoch 230/400\n",
      "24/24 [==============================] - 0s 269us/step - loss: 0.1150\n",
      "Epoch 231/400\n",
      "24/24 [==============================] - 0s 214us/step - loss: 0.1282\n",
      "Epoch 232/400\n",
      "24/24 [==============================] - 0s 189us/step - loss: 0.1054\n",
      "Epoch 233/400\n",
      "24/24 [==============================] - 0s 166us/step - loss: 0.1456\n",
      "Epoch 234/400\n",
      "24/24 [==============================] - 0s 260us/step - loss: 0.1417\n",
      "Epoch 235/400\n",
      "24/24 [==============================] - 0s 159us/step - loss: 0.1048\n",
      "Epoch 236/400\n",
      "24/24 [==============================] - 0s 239us/step - loss: 0.0951\n",
      "Epoch 237/400\n",
      "24/24 [==============================] - 0s 513us/step - loss: 0.1142\n",
      "Epoch 238/400\n",
      "24/24 [==============================] - 0s 254us/step - loss: 0.1396\n",
      "Epoch 239/400\n",
      "24/24 [==============================] - 0s 182us/step - loss: 0.0810\n",
      "Epoch 240/400\n",
      "24/24 [==============================] - 0s 503us/step - loss: 0.0871\n",
      "Epoch 241/400\n",
      "24/24 [==============================] - 0s 586us/step - loss: 0.1013\n",
      "Epoch 242/400\n",
      "24/24 [==============================] - 0s 374us/step - loss: 0.0856\n",
      "Epoch 243/400\n",
      "24/24 [==============================] - 0s 226us/step - loss: 0.1402\n",
      "Epoch 244/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.1355\n",
      "Epoch 245/400\n",
      "24/24 [==============================] - 0s 188us/step - loss: 0.1160\n",
      "Epoch 246/400\n",
      "24/24 [==============================] - 0s 263us/step - loss: 0.1071\n",
      "Epoch 247/400\n",
      "24/24 [==============================] - 0s 315us/step - loss: 0.1026\n",
      "Epoch 248/400\n",
      "24/24 [==============================] - 0s 674us/step - loss: 0.1058\n",
      "Epoch 249/400\n",
      "24/24 [==============================] - 0s 590us/step - loss: 0.1169\n",
      "Epoch 250/400\n",
      "24/24 [==============================] - 0s 378us/step - loss: 0.1388\n",
      "Epoch 251/400\n",
      "24/24 [==============================] - 0s 622us/step - loss: 0.1564\n",
      "Epoch 252/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.1078\n",
      "Epoch 253/400\n",
      "24/24 [==============================] - 0s 160us/step - loss: 0.0812\n",
      "Epoch 254/400\n",
      "24/24 [==============================] - 0s 581us/step - loss: 0.0769\n",
      "Epoch 255/400\n",
      "24/24 [==============================] - 0s 563us/step - loss: 0.1071\n",
      "Epoch 256/400\n",
      "24/24 [==============================] - 0s 240us/step - loss: 0.1270\n",
      "Epoch 257/400\n",
      "24/24 [==============================] - 0s 438us/step - loss: 0.1559\n",
      "Epoch 258/400\n",
      "24/24 [==============================] - 0s 280us/step - loss: 0.1371\n",
      "Epoch 259/400\n",
      "24/24 [==============================] - 0s 311us/step - loss: 0.1323\n",
      "Epoch 260/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.0927\n",
      "Epoch 261/400\n",
      "24/24 [==============================] - 0s 674us/step - loss: 0.1055\n",
      "Epoch 262/400\n",
      "24/24 [==============================] - 0s 273us/step - loss: 0.1336\n",
      "Epoch 263/400\n",
      "24/24 [==============================] - 0s 722us/step - loss: 0.1100\n",
      "Epoch 264/400\n",
      "24/24 [==============================] - 0s 277us/step - loss: 0.1192\n",
      "Epoch 265/400\n",
      "24/24 [==============================] - 0s 188us/step - loss: 0.0829\n",
      "Epoch 266/400\n",
      "24/24 [==============================] - 0s 464us/step - loss: 0.0929\n",
      "Epoch 267/400\n",
      "24/24 [==============================] - 0s 512us/step - loss: 0.0810\n",
      "Epoch 268/400\n",
      "24/24 [==============================] - 0s 364us/step - loss: 0.1069\n",
      "Epoch 269/400\n",
      "24/24 [==============================] - 0s 294us/step - loss: 0.0897\n",
      "Epoch 270/400\n",
      "24/24 [==============================] - 0s 651us/step - loss: 0.1005\n",
      "Epoch 271/400\n",
      "24/24 [==============================] - 0s 390us/step - loss: 0.1232\n",
      "Epoch 272/400\n",
      "24/24 [==============================] - 0s 509us/step - loss: 0.1092\n",
      "Epoch 273/400\n",
      "24/24 [==============================] - 0s 219us/step - loss: 0.1348\n",
      "Epoch 274/400\n",
      "24/24 [==============================] - 0s 260us/step - loss: 0.1356\n",
      "Epoch 275/400\n",
      "24/24 [==============================] - 0s 447us/step - loss: 0.1313\n",
      "Epoch 276/400\n",
      "24/24 [==============================] - 0s 176us/step - loss: 0.0780\n",
      "Epoch 277/400\n",
      "24/24 [==============================] - 0s 174us/step - loss: 0.0869\n",
      "Epoch 278/400\n",
      "24/24 [==============================] - 0s 474us/step - loss: 0.0877\n",
      "Epoch 279/400\n",
      "24/24 [==============================] - 0s 184us/step - loss: 0.0929\n",
      "Epoch 280/400\n",
      "24/24 [==============================] - 0s 297us/step - loss: 0.0911\n",
      "Epoch 281/400\n",
      "24/24 [==============================] - 0s 169us/step - loss: 0.1192\n",
      "Epoch 282/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0831\n",
      "Epoch 283/400\n",
      "24/24 [==============================] - 0s 382us/step - loss: 0.1344\n",
      "Epoch 284/400\n",
      "24/24 [==============================] - 0s 278us/step - loss: 0.0870\n",
      "Epoch 285/400\n",
      "24/24 [==============================] - 0s 196us/step - loss: 0.1008\n",
      "Epoch 286/400\n",
      "24/24 [==============================] - 0s 291us/step - loss: 0.1443\n",
      "Epoch 287/400\n",
      "24/24 [==============================] - 0s 193us/step - loss: 0.1729\n",
      "Epoch 288/400\n",
      "24/24 [==============================] - 0s 296us/step - loss: 0.0994\n",
      "Epoch 289/400\n",
      "24/24 [==============================] - 0s 285us/step - loss: 0.0784\n",
      "Epoch 290/400\n",
      "24/24 [==============================] - 0s 249us/step - loss: 0.0954\n",
      "Epoch 291/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.1142\n",
      "Epoch 292/400\n",
      "24/24 [==============================] - 0s 164us/step - loss: 0.1181\n",
      "Epoch 293/400\n",
      "24/24 [==============================] - 0s 395us/step - loss: 0.1647\n",
      "Epoch 294/400\n",
      "24/24 [==============================] - 0s 266us/step - loss: 0.0924\n",
      "Epoch 295/400\n",
      "24/24 [==============================] - 0s 362us/step - loss: 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/400\n",
      "24/24 [==============================] - 0s 558us/step - loss: 0.0805\n",
      "Epoch 297/400\n",
      "24/24 [==============================] - 0s 639us/step - loss: 0.0993\n",
      "Epoch 298/400\n",
      "24/24 [==============================] - 0s 348us/step - loss: 0.1352\n",
      "Epoch 299/400\n",
      "24/24 [==============================] - 0s 525us/step - loss: 0.1074\n",
      "Epoch 300/400\n",
      "24/24 [==============================] - 0s 217us/step - loss: 0.0853\n",
      "Epoch 301/400\n",
      "24/24 [==============================] - 0s 248us/step - loss: 0.1316\n",
      "Epoch 302/400\n",
      "24/24 [==============================] - 0s 195us/step - loss: 0.1374\n",
      "Epoch 303/400\n",
      "24/24 [==============================] - 0s 161us/step - loss: 0.0971\n",
      "Epoch 304/400\n",
      "24/24 [==============================] - 0s 168us/step - loss: 0.1124\n",
      "Epoch 305/400\n",
      "24/24 [==============================] - 0s 239us/step - loss: 0.1115\n",
      "Epoch 306/400\n",
      "24/24 [==============================] - 0s 442us/step - loss: 0.1174\n",
      "Epoch 307/400\n",
      "24/24 [==============================] - 0s 543us/step - loss: 0.0724\n",
      "Epoch 308/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.0760\n",
      "Epoch 309/400\n",
      "24/24 [==============================] - 0s 188us/step - loss: 0.0940\n",
      "Epoch 310/400\n",
      "24/24 [==============================] - 0s 140us/step - loss: 0.1315\n",
      "Epoch 311/400\n",
      "24/24 [==============================] - 0s 273us/step - loss: 0.0954\n",
      "Epoch 312/400\n",
      "24/24 [==============================] - 0s 430us/step - loss: 0.1254\n",
      "Epoch 313/400\n",
      "24/24 [==============================] - 0s 620us/step - loss: 0.1283\n",
      "Epoch 314/400\n",
      "24/24 [==============================] - 0s 299us/step - loss: 0.1195\n",
      "Epoch 315/400\n",
      "24/24 [==============================] - 0s 473us/step - loss: 0.0722\n",
      "Epoch 316/400\n",
      "24/24 [==============================] - 0s 217us/step - loss: 0.0758\n",
      "Epoch 317/400\n",
      "24/24 [==============================] - 0s 509us/step - loss: 0.0892\n",
      "Epoch 318/400\n",
      "24/24 [==============================] - 0s 662us/step - loss: 0.1307\n",
      "Epoch 319/400\n",
      "24/24 [==============================] - 0s 519us/step - loss: 0.0851\n",
      "Epoch 320/400\n",
      "24/24 [==============================] - 0s 604us/step - loss: 0.1449\n",
      "Epoch 321/400\n",
      "24/24 [==============================] - 0s 386us/step - loss: 0.0967\n",
      "Epoch 322/400\n",
      "24/24 [==============================] - 0s 305us/step - loss: 0.1212\n",
      "Epoch 323/400\n",
      "24/24 [==============================] - 0s 290us/step - loss: 0.1431\n",
      "Epoch 324/400\n",
      "24/24 [==============================] - 0s 379us/step - loss: 0.0936\n",
      "Epoch 325/400\n",
      "24/24 [==============================] - 0s 171us/step - loss: 0.0945\n",
      "Epoch 326/400\n",
      "24/24 [==============================] - 0s 288us/step - loss: 0.0907\n",
      "Epoch 327/400\n",
      "24/24 [==============================] - 0s 193us/step - loss: 0.0948\n",
      "Epoch 328/400\n",
      "24/24 [==============================] - 0s 331us/step - loss: 0.0721\n",
      "Epoch 329/400\n",
      "24/24 [==============================] - 0s 345us/step - loss: 0.0935\n",
      "Epoch 330/400\n",
      "24/24 [==============================] - 0s 200us/step - loss: 0.0903\n",
      "Epoch 331/400\n",
      "24/24 [==============================] - 0s 180us/step - loss: 0.0858\n",
      "Epoch 332/400\n",
      "24/24 [==============================] - 0s 699us/step - loss: 0.0990\n",
      "Epoch 333/400\n",
      "24/24 [==============================] - 0s 239us/step - loss: 0.1211\n",
      "Epoch 334/400\n",
      "24/24 [==============================] - 0s 301us/step - loss: 0.1501\n",
      "Epoch 335/400\n",
      "24/24 [==============================] - 0s 173us/step - loss: 0.1334\n",
      "Epoch 336/400\n",
      "24/24 [==============================] - 0s 287us/step - loss: 0.1043\n",
      "Epoch 337/400\n",
      "24/24 [==============================] - 0s 189us/step - loss: 0.0672\n",
      "Epoch 338/400\n",
      "24/24 [==============================] - 0s 128us/step - loss: 0.0882\n",
      "Epoch 339/400\n",
      "24/24 [==============================] - 0s 135us/step - loss: 0.0936\n",
      "Epoch 340/400\n",
      "24/24 [==============================] - 0s 190us/step - loss: 0.1148\n",
      "Epoch 341/400\n",
      "24/24 [==============================] - 0s 241us/step - loss: 0.1077\n",
      "Epoch 342/400\n",
      "24/24 [==============================] - 0s 436us/step - loss: 0.1300\n",
      "Epoch 343/400\n",
      "24/24 [==============================] - 0s 486us/step - loss: 0.0817\n",
      "Epoch 344/400\n",
      "24/24 [==============================] - 0s 509us/step - loss: 0.0898\n",
      "Epoch 345/400\n",
      "24/24 [==============================] - 0s 463us/step - loss: 0.0972\n",
      "Epoch 346/400\n",
      "24/24 [==============================] - 0s 685us/step - loss: 0.1211\n",
      "Epoch 347/400\n",
      "24/24 [==============================] - 0s 453us/step - loss: 0.1227\n",
      "Epoch 348/400\n",
      "24/24 [==============================] - 0s 437us/step - loss: 0.1156\n",
      "Epoch 349/400\n",
      "24/24 [==============================] - 0s 388us/step - loss: 0.1011\n",
      "Epoch 350/400\n",
      "24/24 [==============================] - 0s 515us/step - loss: 0.1227\n",
      "Epoch 351/400\n",
      "24/24 [==============================] - 0s 422us/step - loss: 0.0708\n",
      "Epoch 352/400\n",
      "24/24 [==============================] - 0s 216us/step - loss: 0.0796\n",
      "Epoch 353/400\n",
      "24/24 [==============================] - 0s 176us/step - loss: 0.0838\n",
      "Epoch 354/400\n",
      "24/24 [==============================] - 0s 380us/step - loss: 0.0887\n",
      "Epoch 355/400\n",
      "24/24 [==============================] - 0s 542us/step - loss: 0.1280\n",
      "Epoch 356/400\n",
      "24/24 [==============================] - 0s 301us/step - loss: 0.0995\n",
      "Epoch 357/400\n",
      "24/24 [==============================] - 0s 329us/step - loss: 0.1113\n",
      "Epoch 358/400\n",
      "24/24 [==============================] - 0s 450us/step - loss: 0.1153\n",
      "Epoch 359/400\n",
      "24/24 [==============================] - 0s 663us/step - loss: 0.0781\n",
      "Epoch 360/400\n",
      "24/24 [==============================] - 0s 459us/step - loss: 0.0825\n",
      "Epoch 361/400\n",
      "24/24 [==============================] - 0s 223us/step - loss: 0.0704\n",
      "Epoch 362/400\n",
      "24/24 [==============================] - 0s 362us/step - loss: 0.0876\n",
      "Epoch 363/400\n",
      "24/24 [==============================] - 0s 354us/step - loss: 0.1044\n",
      "Epoch 364/400\n",
      "24/24 [==============================] - 0s 216us/step - loss: 0.1102\n",
      "Epoch 365/400\n",
      "24/24 [==============================] - 0s 282us/step - loss: 0.1511\n",
      "Epoch 366/400\n",
      "24/24 [==============================] - 0s 452us/step - loss: 0.0915\n",
      "Epoch 367/400\n",
      "24/24 [==============================] - 0s 171us/step - loss: 0.0863\n",
      "Epoch 368/400\n",
      "24/24 [==============================] - 0s 274us/step - loss: 0.0887\n",
      "Epoch 369/400\n",
      "24/24 [==============================] - 0s 273us/step - loss: 0.1147\n",
      "Epoch 370/400\n",
      "24/24 [==============================] - 0s 511us/step - loss: 0.1499\n",
      "Epoch 371/400\n",
      "24/24 [==============================] - 0s 147us/step - loss: 0.1068\n",
      "Epoch 372/400\n",
      "24/24 [==============================] - 0s 353us/step - loss: 0.0736\n",
      "Epoch 373/400\n",
      "24/24 [==============================] - 0s 527us/step - loss: 0.1014\n",
      "Epoch 374/400\n",
      "24/24 [==============================] - 0s 196us/step - loss: 0.0741\n",
      "Epoch 375/400\n",
      "24/24 [==============================] - 0s 176us/step - loss: 0.1006\n",
      "Epoch 376/400\n",
      "24/24 [==============================] - 0s 441us/step - loss: 0.0696\n",
      "Epoch 377/400\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0764\n",
      "Epoch 378/400\n",
      "24/24 [==============================] - 0s 404us/step - loss: 0.1018\n",
      "Epoch 379/400\n",
      "24/24 [==============================] - 0s 399us/step - loss: 0.1034\n",
      "Epoch 380/400\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0916\n",
      "Epoch 381/400\n",
      "24/24 [==============================] - 0s 332us/step - loss: 0.0821\n",
      "Epoch 382/400\n",
      "24/24 [==============================] - 0s 468us/step - loss: 0.1031\n",
      "Epoch 383/400\n",
      "24/24 [==============================] - 0s 695us/step - loss: 0.0841\n",
      "Epoch 384/400\n",
      "24/24 [==============================] - 0s 314us/step - loss: 0.1063\n",
      "Epoch 385/400\n",
      "24/24 [==============================] - 0s 453us/step - loss: 0.1328\n",
      "Epoch 386/400\n",
      "24/24 [==============================] - 0s 469us/step - loss: 0.1381\n",
      "Epoch 387/400\n",
      "24/24 [==============================] - 0s 466us/step - loss: 0.0853\n",
      "Epoch 388/400\n",
      "24/24 [==============================] - 0s 342us/step - loss: 0.0771\n",
      "Epoch 389/400\n",
      "24/24 [==============================] - 0s 233us/step - loss: 0.0692\n",
      "Epoch 390/400\n",
      "24/24 [==============================] - 0s 265us/step - loss: 0.0780\n",
      "Epoch 391/400\n",
      "24/24 [==============================] - 0s 353us/step - loss: 0.0669\n",
      "Epoch 392/400\n",
      "24/24 [==============================] - 0s 163us/step - loss: 0.0890\n",
      "Epoch 393/400\n",
      "24/24 [==============================] - 0s 304us/step - loss: 0.1155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/400\n",
      "24/24 [==============================] - 0s 385us/step - loss: 0.1554\n",
      "Epoch 395/400\n",
      "24/24 [==============================] - 0s 172us/step - loss: 0.0846\n",
      "Epoch 396/400\n",
      "24/24 [==============================] - 0s 475us/step - loss: 0.0980\n",
      "Epoch 397/400\n",
      "24/24 [==============================] - 0s 342us/step - loss: 0.1088\n",
      "Epoch 398/400\n",
      "24/24 [==============================] - 0s 170us/step - loss: 0.0795\n",
      "Epoch 399/400\n",
      "24/24 [==============================] - 0s 374us/step - loss: 0.0891\n",
      "Epoch 400/400\n",
      "24/24 [==============================] - 0s 197us/step - loss: 0.0911\n",
      "best epoch =  391\n",
      "smallest loss = 0.06692367047071457\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 100, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "#historyData = model.fit(xarray,yarray,epochs=500,callbacks=[es])\n",
    "historyData = model.fit(X_train,Y_train,epochs=400,callbacks=[es]) \n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dec40c",
   "metadata": {},
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9520a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  22.4 , power=  75.2 ,  predicted voltage_to_load =  23.530138581991196 , predicted power=  78.51596255898475\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  26.9 , power=  81.1 ,  predicted voltage_to_load =  26.131470552086828 , predicted power=  88.68480907678604\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  26.5 , power=  104.9 ,  predicted voltage_to_load =  26.165189650654792 , predicted power=  99.8244466304779\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  29.0 , power=  189.4 ,  predicted voltage_to_load =  31.31454594731331 , predicted power=  201.3667463302612\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  26.5 , power=  78.6 ,  predicted voltage_to_load =  25.696956422924995 , predicted power=  86.50567379593849\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  23.5 , power=  124.6 ,  predicted voltage_to_load =  24.601820388436316 , predicted power=  116.2963616847992\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  25.8 , power=  99.7 ,  predicted voltage_to_load =  25.605833822488783 , predicted power=  103.40209401845931\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  23.5 , power=  62.2 ,  predicted voltage_to_load =  23.843605750799178 , predicted power=  71.41324988603591\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  26.3 , power=  77.6 ,  predicted voltage_to_load =  25.297257089614867 , predicted power=  80.03380316495895\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  6.696 , voltage_to_load=  30.099999999999998 , power=  135.5 ,  predicted voltage_to_load =  30.848176193237304 , predicted power=  169.0957857608795\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  30.600000000000005 , power=  105.20000000000002 ,  predicted voltage_to_load =  30.23843878507614 , predicted power=  131.32931823730468\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  27.099999999999998 , power=  82.7 ,  predicted voltage_to_load =  25.890245306491853 , predicted power=  84.09346012473105\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  26.4 , power=  156.7 ,  predicted voltage_to_load =  28.362327563762666 , predicted power=  161.9338085889816\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  6.696 , voltage_to_load=  28.3 , power=  119.6 ,  predicted voltage_to_load =  29.32336286306381 , predicted power=  144.4074114561081\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  4.464 , voltage_to_load=  28.100000000000005 , power=  177.7 ,  predicted voltage_to_load =  30.159337323904037 , predicted power=  184.69079147577284\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  28.100000000000005 , power=  118.20000000000002 ,  predicted voltage_to_load =  27.743515574932097 , predicted power=  122.90424890518187\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.0 ,  predicted voltage_to_load =  25.709023281931877 , predicted power=  99.70437232851981\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.2 , power=  83.1 ,  predicted voltage_to_load =  24.641793632507323 , predicted power=  107.83023141622543\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.4 , power=  84.7 ,  predicted voltage_to_load =  26.118645375967024 , predicted power=  132.60486829280853\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  25.6 , power=  146.9 ,  predicted voltage_to_load =  27.500195103883744 , predicted power=  159.58721365928648\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  18.9 , power=  80.3 ,  predicted voltage_to_load =  23.35086201131344 , predicted power=  95.95297667980194\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  23.6 , power=  83.7 ,  predicted voltage_to_load =  24.74533308446407 , predicted power=  86.87306834459304\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  28.100000000000005 , power=  88.7 ,  predicted voltage_to_load =  27.177631282806395 , predicted power=  92.2389189183712\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  27.599999999999998 , power=  113.80000000000001 ,  predicted voltage_to_load =  27.983988809585572 , predicted power=  122.0087481856346\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "outpt=[]\n",
    "\n",
    "Tamed = 10\n",
    "IDmed = 800.\n",
    "RLmed = 6.696\n",
    "VLmed = 26.45\n",
    "Wdmed = 100.1\n",
    "\n",
    "\n",
    "#first point (row [0])comparison of data and prediction\n",
    "# put in a loop to print comparion for all data points\n",
    "for i in range(len(X_train)):\n",
    "    \n",
    "    test = [[ X_train[i][0] , X_train[i][1] , X_train[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    print ('row [0] data:  T1= ', X_train[i][0]*Tamed, ', gam= ', X_train[i][1]*IDmed, \\\n",
    "        ', qsol= ', X_train[i][2]*RLmed,', voltage_to_load= ', Y_train[i][0]*VLmed,\\\n",
    "        ', power= ', Y_train[i][1]*Wdmed,',  predicted voltage_to_load = ', outpt[0][0]*VLmed,\\\n",
    "           ', predicted power= ', outpt[0][1]*Wdmed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442c013",
   "metadata": {},
   "source": [
    "# (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1579c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  22.4 , power=  75.2 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  26.9 , power=  81.1 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  26.5 , power=  104.9 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  29.0 , power=  189.4 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  26.5 , power=  78.6 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  23.5 , power=  124.6 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  25.8 , power=  99.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  8.928 , voltage_to_load=  23.5 , power=  62.2 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  26.3 , power=  77.6 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  6.696 , voltage_to_load=  30.099999999999998 , power=  135.5 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  1250.0 , qsol=  8.928 , voltage_to_load=  30.600000000000005 , power=  105.20000000000002 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  650.0 , qsol=  8.928 , voltage_to_load=  27.099999999999998 , power=  82.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  4.464 , voltage_to_load=  26.4 , power=  156.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  1250.0 , qsol=  6.696 , voltage_to_load=  28.3 , power=  119.6 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  950.0 , qsol=  4.464 , voltage_to_load=  28.100000000000005 , power=  177.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  650.0 , qsol=  6.696 , voltage_to_load=  28.100000000000005 , power=  118.20000000000002 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  24.8 , power=  92.0 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.2 , power=  83.1 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  30.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  19.4 , power=  84.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  1250.0 , qsol=  4.464 , voltage_to_load=  25.6 , power=  146.9 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  -10.0 , gam=  350.0 , qsol=  4.464 , voltage_to_load=  18.9 , power=  80.3 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  350.0 , qsol=  6.696 , voltage_to_load=  23.6 , power=  83.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  8.928 , voltage_to_load=  28.100000000000005 , power=  88.7 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n",
      "row [0] data:  T1=  10.0 , gam=  950.0 , qsol=  6.696 , voltage_to_load=  27.599999999999998 , power=  113.80000000000001 ,  predicted voltage_to_load =  27.3 , predicted power=  167.5\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "outpt=[]\n",
    "\n",
    "Tamed = 10\n",
    "IDmed = 800.\n",
    "RLmed = 6.696\n",
    "VLmed = 26.45\n",
    "Wdmed = 100.1\n",
    "\n",
    "\n",
    "#first point (row [0])comparison of data and prediction\n",
    "# put in a loop to print comparion for all data points\n",
    "for i in range(len(X_train)):\n",
    "    \n",
    "    test = [[ X_train[i][0] , X_train[i][1] , X_train[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "\n",
    "    print ('row [0] data:  T1= ', X_train[i][0]*Tamed, ', gam= ', X_train[i][1]*IDmed, \\\n",
    "        ', qsol= ', X_train[i][2]*RLmed,', voltage_to_load= ', Y_train[i][0]*VLmed,\\\n",
    "        ', power= ', Y_train[i][1]*Wdmed,',  predicted voltage_to_load = ', Y_test[0][0]*VLmed,\\\n",
    "           ', predicted power= ', Y_test[0][1]*Wdmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
